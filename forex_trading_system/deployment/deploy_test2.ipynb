{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Optional, Tuple, List\n",
    "from pathlib import Path\n",
    "import threading\n",
    "from queue import Queue\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pytz\n",
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "\n",
    "# Trading components\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "\n",
    "# OANDA components\n",
    "from oandapyV20 import API\n",
    "import oandapyV20.endpoints.positions as positions\n",
    "import oandapyV20.endpoints.orders as orders\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "import oandapyV20.endpoints.trades as trades\n",
    "\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import local components\n",
    "from trading.environments.forex_env2_flat import ForexTradingEnv\n",
    "from data_management.preprocessor import DataPreprocessor\n",
    "from data_management.indicator_manager import IndicatorManager\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('trading_system.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('trading_system')\n",
    "\n",
    "# OANDA Configuration\n",
    "OANDA_API_KEY = '9317ace4596d61e3e98b1a53b2342483-45d3ad4084c80b111727a9fada9ef0ff'\n",
    "OANDA_ACCOUNT_ID = '101-004-30348600-001' #running account\n",
    "# OANDA_ACCOUNT_ID = '101-004-30348600-002'\n",
    "OANDA_ENV = 'practice'\n",
    "\n",
    "# Initialize OANDA client\n",
    "client = API(access_token=OANDA_API_KEY, environment=OANDA_ENV)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TradeRecord:\n",
    "    \"\"\"Detailed record of a single trade.\"\"\"\n",
    "    pair: str\n",
    "    entry_time: datetime\n",
    "    exit_time: Optional[datetime]\n",
    "    entry_price: float\n",
    "    exit_price: Optional[float]\n",
    "    position_type: str  # 'LONG' or 'SHORT'\n",
    "    size: float\n",
    "    pnl: float\n",
    "    pnl_percentage: float\n",
    "    trade_duration: timedelta\n",
    "    spread_entry: float\n",
    "    spread_exit: Optional[float]\n",
    "    model_version: str\n",
    "    market_session: str\n",
    "    entry_indicators: Dict[str, float]  # Key indicator values at entry\n",
    "    exit_indicators: Optional[Dict[str, float]]  # Key indicator values at exit\n",
    "\n",
    "@dataclass\n",
    "class PairPerformanceMetrics:\n",
    "    \"\"\"Performance metrics for a single currency pair.\"\"\"\n",
    "    total_trades: int = 0\n",
    "    winning_trades: int = 0\n",
    "    losing_trades: int = 0\n",
    "    total_pnl: float = 0.0\n",
    "    peak_balance: float = 0.0\n",
    "    max_drawdown: float = 0.0\n",
    "    avg_trade_duration: timedelta = timedelta(0)\n",
    "    win_rate: float = 0.0\n",
    "    profit_factor: float = 0.0\n",
    "    sharpe_ratio: float = 0.0\n",
    "    model_version: str = \"\"\n",
    "    last_retrain_date: Optional[datetime] = None\n",
    "    performance_by_session: Dict[str, float] = field(default_factory=dict)\n",
    "    \n",
    "class PerformanceTracker:\n",
    "    \"\"\"Tracks and analyzes trading system performance.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_path: Path):\n",
    "        self.base_path = base_path\n",
    "        self.trades_path = base_path / \"trades\"\n",
    "        self.metrics_path = base_path / \"metrics\"\n",
    "        self.trades_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.metrics_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Initialize storage\n",
    "        self.trade_history: Dict[str, List[TradeRecord]] = {}\n",
    "        self.pair_metrics: Dict[str, PairPerformanceMetrics] = {}\n",
    "        self.error_log: List[Dict] = []\n",
    "        self.model_versions: Dict[str, str] = {}\n",
    "        \n",
    "        # Performance thresholds for alerts\n",
    "        self.thresholds = {\n",
    "            'drawdown_alert': 0.10,  # 10% drawdown\n",
    "            'win_rate_min': 0.45,    # 45% minimum win rate\n",
    "            'trade_frequency_max': 50 # Max trades per day\n",
    "        }\n",
    "        \n",
    "    def record_trade(self, trade: TradeRecord) -> None:\n",
    "        \"\"\"Record a completed trade and update metrics.\"\"\"\n",
    "        pair = trade.pair\n",
    "        \n",
    "        # Store trade record\n",
    "        if pair not in self.trade_history:\n",
    "            self.trade_history[pair] = []\n",
    "        self.trade_history[pair].append(trade)\n",
    "        \n",
    "        # Update pair metrics\n",
    "        if pair not in self.pair_metrics:\n",
    "            self.pair_metrics[pair] = PairPerformanceMetrics()\n",
    "        \n",
    "        metrics = self.pair_metrics[pair]\n",
    "        metrics.total_trades += 1\n",
    "        metrics.total_pnl += trade.pnl\n",
    "        \n",
    "        if trade.pnl > 0:\n",
    "            metrics.winning_trades += 1\n",
    "        else:\n",
    "            metrics.losing_trades += 1\n",
    "            \n",
    "        # Update win rate and other metrics\n",
    "        self._update_pair_metrics(pair)\n",
    "        \n",
    "        # Check for performance alerts\n",
    "        self._check_performance_alerts(pair)\n",
    "        \n",
    "    def _update_pair_metrics(self, pair: str) -> None:\n",
    "        \"\"\"Update detailed metrics for a currency pair.\"\"\"\n",
    "        metrics = self.pair_metrics[pair]\n",
    "        trades = self.trade_history[pair]\n",
    "        \n",
    "        if not trades:\n",
    "            return\n",
    "            \n",
    "        # Calculate basic metrics\n",
    "        metrics.win_rate = metrics.winning_trades / metrics.total_trades\n",
    "        \n",
    "        # Calculate profit factor\n",
    "        winning_pnl = sum(t.pnl for t in trades if t.pnl > 0)\n",
    "        losing_pnl = abs(sum(t.pnl for t in trades if t.pnl < 0))\n",
    "        metrics.profit_factor = winning_pnl / losing_pnl if losing_pnl != 0 else float('inf')\n",
    "        \n",
    "        # Calculate drawdown\n",
    "        cumulative_pnl = np.cumsum([t.pnl for t in trades])\n",
    "        peak = np.maximum.accumulate(cumulative_pnl)\n",
    "        drawdown = (peak - cumulative_pnl) / peak\n",
    "        metrics.max_drawdown = np.max(drawdown)\n",
    "        \n",
    "        # Calculate session performance\n",
    "        session_pnl = {}\n",
    "        for trade in trades:\n",
    "            session = trade.market_session\n",
    "            session_pnl[session] = session_pnl.get(session, 0) + trade.pnl\n",
    "        metrics.performance_by_session = session_pnl\n",
    "        \n",
    "        # Save updated metrics\n",
    "        self._save_pair_metrics(pair)\n",
    "        \n",
    "    def _check_performance_alerts(self, pair: str) -> None:\n",
    "        \"\"\"Check for performance issues that require attention.\"\"\"\n",
    "        metrics = self.pair_metrics[pair]\n",
    "        alerts = []\n",
    "        \n",
    "        # Check drawdown\n",
    "        if metrics.max_drawdown >= self.thresholds['drawdown_alert']:\n",
    "            alerts.append(f\"High drawdown alert: {metrics.max_drawdown:.1%}\")\n",
    "            \n",
    "        # Check win rate\n",
    "        if metrics.total_trades >= 20 and metrics.win_rate < self.thresholds['win_rate_min']:\n",
    "            alerts.append(f\"Low win rate alert: {metrics.win_rate:.1%}\")\n",
    "            \n",
    "        # Check trade frequency\n",
    "        recent_trades = [t for t in self.trade_history[pair] \n",
    "                        if t.entry_time > datetime.now() - timedelta(days=1)]\n",
    "        if len(recent_trades) > self.thresholds['trade_frequency_max']:\n",
    "            alerts.append(\"High trade frequency alert\")\n",
    "            \n",
    "        if alerts:\n",
    "            logging.warning(f\"Performance alerts for {pair}:\\n\" + \"\\n\".join(alerts))\n",
    "            \n",
    "    def analyze_model_performance(self, pair: str) -> pd.DataFrame:\n",
    "        \"\"\"Analyze performance metrics by model version.\"\"\"\n",
    "        if pair not in self.trade_history:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        trades = self.trade_history[pair]\n",
    "        df = pd.DataFrame([{\n",
    "            'model_version': t.model_version,\n",
    "            'entry_time': t.entry_time,\n",
    "            'pnl': t.pnl,\n",
    "            'trade_duration': t.trade_duration,\n",
    "            'market_session': t.market_session\n",
    "        } for t in trades])\n",
    "        \n",
    "        return df.groupby('model_version').agg({\n",
    "            'pnl': ['count', 'sum', 'mean', 'std'],\n",
    "            'trade_duration': 'mean'\n",
    "        })\n",
    "        \n",
    "    def get_pair_summary(self, pair: str, lookback_days: int = 30) -> Dict:\n",
    "        \"\"\"Get comprehensive performance summary for a pair.\"\"\"\n",
    "        if pair not in self.pair_metrics:\n",
    "            return {}\n",
    "            \n",
    "        metrics = self.pair_metrics[pair]\n",
    "        recent_trades = [t for t in self.trade_history[pair] \n",
    "                        if t.entry_time > datetime.now() - timedelta(days=lookback_days)]\n",
    "        \n",
    "        return {\n",
    "            'total_trades': metrics.total_trades,\n",
    "            'win_rate': metrics.win_rate,\n",
    "            'total_pnl': metrics.total_pnl,\n",
    "            'max_drawdown': metrics.max_drawdown,\n",
    "            'profit_factor': metrics.profit_factor,\n",
    "            'performance_by_session': metrics.performance_by_session,\n",
    "            'recent_trades_count': len(recent_trades),\n",
    "            'model_version': metrics.model_version,\n",
    "            'last_retrain': metrics.last_retrain_date\n",
    "        }\n",
    "        \n",
    "    def _save_pair_metrics(self, pair: str) -> None:\n",
    "        \"\"\"Save pair metrics to disk.\"\"\"\n",
    "        metrics = self.pair_metrics[pair]\n",
    "        \n",
    "        # Convert to serializable format\n",
    "        metrics_dict = {\n",
    "            'total_trades': metrics.total_trades,\n",
    "            'winning_trades': metrics.winning_trades,\n",
    "            'total_pnl': metrics.total_pnl,\n",
    "            'max_drawdown': metrics.max_drawdown,\n",
    "            'win_rate': metrics.win_rate,\n",
    "            'profit_factor': metrics.profit_factor,\n",
    "            'model_version': metrics.model_version,\n",
    "            'last_retrain_date': metrics.last_retrain_date.isoformat() \n",
    "                if metrics.last_retrain_date else None,\n",
    "            'performance_by_session': metrics.performance_by_session\n",
    "        }\n",
    "        \n",
    "        # Save to file\n",
    "        metrics_file = self.metrics_path / f\"{pair}_metrics.json\"\n",
    "        with open(metrics_file, 'w') as f:\n",
    "            json.dump(metrics_dict, f, indent=2)\n",
    "            \n",
    "    def export_performance_report(self, lookback_days: Optional[int] = None) -> str:\n",
    "        \"\"\"Generate a comprehensive performance report.\"\"\"\n",
    "        report = [\"Trading System Performance Report\\n\"]\n",
    "        report.append(f\"Generated at: {datetime.now()}\\n\")\n",
    "        \n",
    "        for pair in sorted(self.pair_metrics.keys()):\n",
    "            metrics = self.pair_metrics[pair]\n",
    "            trades = self.trade_history[pair]\n",
    "            \n",
    "            if lookback_days:\n",
    "                trades = [t for t in trades \n",
    "                         if t.entry_time > datetime.now() - timedelta(days=lookback_days)]\n",
    "            \n",
    "            report.append(f\"\\n{pair} Performance:\")\n",
    "            report.append(f\"Total Trades: {metrics.total_trades}\")\n",
    "            report.append(f\"Win Rate: {metrics.win_rate:.1%}\")\n",
    "            report.append(f\"Total PnL: {metrics.total_pnl:,.2f}\")\n",
    "            report.append(f\"Max Drawdown: {metrics.max_drawdown:.1%}\")\n",
    "            report.append(f\"Profit Factor: {metrics.profit_factor:.2f}\")\n",
    "            report.append(\"\\nPerformance by Session:\")\n",
    "            \n",
    "            for session, pnl in metrics.performance_by_session.items():\n",
    "                report.append(f\"  {session}: {pnl:,.2f}\")\n",
    "                \n",
    "            report.append(f\"\\nCurrent Model: {metrics.model_version}\")\n",
    "            if metrics.last_retrain_date:\n",
    "                report.append(f\"Last Retrain: {metrics.last_retrain_date}\")\n",
    "                \n",
    "        return \"\\n\".join(report)\n",
    "\n",
    "class PositionManager:\n",
    "    \"\"\"Manages trading positions with safety features and position tracking.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        currency_pairs: Dict[str, float],\n",
    "        logger: Optional[logging.Logger] = None,\n",
    "        account_id: str = OANDA_ACCOUNT_ID,\n",
    "        client: API = API(access_token=OANDA_API_KEY, environment=OANDA_ENV),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the position manager.\n",
    "        \n",
    "        Args:\n",
    "            client: OANDA API client\n",
    "            account_id: OANDA account ID\n",
    "            currency_pairs: Dictionary of currency pairs and their position sizes\n",
    "            logger: Optional logger instance\n",
    "        \"\"\"\n",
    "        self.client = client\n",
    "        self.account_id = account_id\n",
    "        self.currency_pairs = currency_pairs\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "        self.positions = {}\n",
    "        self.last_sync_time = None\n",
    "        \n",
    "    def close_all_positions(self, confirm: bool = True) -> bool:\n",
    "        \"\"\"\n",
    "        Close all open positions with confirmation option.\n",
    "        \n",
    "        Args:\n",
    "            confirm: If True, requires confirmation before closing positions\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if all positions closed successfully\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get current positions\n",
    "            r = positions.OpenPositions(accountID=self.account_id)\n",
    "            response = self.client.request(r)\n",
    "            open_positions = response.get('positions', [])\n",
    "            \n",
    "            if not open_positions:\n",
    "                self.logger.info(\"No open positions to close\")\n",
    "                return True\n",
    "                \n",
    "            # Show positions and get confirmation if required\n",
    "            total_positions = len(open_positions)\n",
    "            if confirm:\n",
    "                print(f\"\\nFound {total_positions} open positions:\")\n",
    "                for pos in open_positions:\n",
    "                    pair = pos['instrument']\n",
    "                    long_units = float(pos.get('long', {}).get('units', 0))\n",
    "                    short_units = float(pos.get('short', {}).get('units', 0))\n",
    "                    print(f\"- {pair}: Long: {long_units}, Short: {short_units}\")\n",
    "                    \n",
    "                confirm_input = input(\"\\nClose all positions? (yes/no): \")\n",
    "                if confirm_input.lower() != 'yes':\n",
    "                    self.logger.info(\"Position closing cancelled by user\")\n",
    "                    return False\n",
    "            \n",
    "            # Close positions\n",
    "            for pos in open_positions:\n",
    "                pair = pos['instrument']\n",
    "                \n",
    "                try:\n",
    "                    # Close long positions\n",
    "                    if float(pos.get('long', {}).get('units', 0)) > 0:\n",
    "                        data = {\"longUnits\": \"ALL\"}\n",
    "                        r = positions.PositionClose(\n",
    "                            accountID=self.account_id,\n",
    "                            instrument=pair,\n",
    "                            data=data\n",
    "                        )\n",
    "                        self.client.request(r)\n",
    "                        self.logger.info(f\"Closed long position for {pair}\")\n",
    "                    \n",
    "                    # Close short positions\n",
    "                    if float(pos.get('short', {}).get('units', 0)) < 0:\n",
    "                        data = {\"shortUnits\": \"ALL\"}\n",
    "                        r = positions.PositionClose(\n",
    "                            accountID=self.account_id,\n",
    "                            instrument=pair,\n",
    "                            data=data\n",
    "                        )\n",
    "                        self.client.request(r)\n",
    "                        self.logger.info(f\"Closed short position for {pair}\")\n",
    "                        \n",
    "                    # Small delay to prevent rate limiting\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error closing position for {pair}: {str(e)}\")\n",
    "                    return False\n",
    "            \n",
    "            # Verify all positions are closed\n",
    "            r = positions.OpenPositions(accountID=self.account_id)\n",
    "            response = self.client.request(r)\n",
    "            remaining_positions = response.get('positions', [])\n",
    "            \n",
    "            if not remaining_positions:\n",
    "                self.logger.info(\"All positions successfully closed\")\n",
    "                return True\n",
    "            else:\n",
    "                self.logger.warning(\n",
    "                    f\"Some positions remain after closing attempt: {len(remaining_positions)} positions\"\n",
    "                )\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in close_all_positions: {str(e)}\")\n",
    "            return False\n",
    "            \n",
    "    def cancel_all_orders(self) -> bool:\n",
    "        \"\"\"Cancel all pending orders.\"\"\"\n",
    "        try:\n",
    "            # Get all pending orders\n",
    "            r = orders.OrderList(accountID=self.account_id)\n",
    "            response = self.client.request(r)\n",
    "            pending_orders = response.get('orders', [])\n",
    "            \n",
    "            if not pending_orders:\n",
    "                self.logger.info(\"No pending orders to cancel\")\n",
    "                return True\n",
    "                \n",
    "            # Cancel each order\n",
    "            for order in pending_orders:\n",
    "                try:\n",
    "                    r = orders.OrderCancel(\n",
    "                        accountID=self.account_id,\n",
    "                        orderID=order['id']\n",
    "                    )\n",
    "                    self.client.request(r)\n",
    "                    self.logger.info(f\"Cancelled order {order['id']}\")\n",
    "                    time.sleep(0.1)  # Rate limiting prevention\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error cancelling order {order['id']}: {str(e)}\")\n",
    "                    return False\n",
    "                    \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in cancel_all_orders: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def emergency_shutdown(self) -> None:\n",
    "        \"\"\"\n",
    "        Emergency shutdown - closes all positions and cancels all orders.\n",
    "        Returns only after confirming all positions are closed.\n",
    "        \"\"\"\n",
    "        self.logger.warning(\"Initiating emergency shutdown...\")\n",
    "        \n",
    "        # First attempt\n",
    "        success = self.close_all_positions(confirm=False)\n",
    "        self.cancel_all_orders()\n",
    "        \n",
    "        # Retry if necessary\n",
    "        if not success:\n",
    "            self.logger.warning(\"First closing attempt failed, retrying...\")\n",
    "            time.sleep(1)\n",
    "            success = self.close_all_positions(confirm=False)\n",
    "            \n",
    "        # Final verification\n",
    "        r = positions.OpenPositions(accountID=self.account_id)\n",
    "        response = self.client.request(r)\n",
    "        remaining_positions = response.get('positions', [])\n",
    "        \n",
    "        if remaining_positions:\n",
    "            self.logger.error(\n",
    "                \"Emergency shutdown incomplete - some positions remain. \"\n",
    "                \"Manual intervention may be required.\"\n",
    "            )\n",
    "        else:\n",
    "            self.logger.info(\"Emergency shutdown completed successfully\")\n",
    "            \n",
    "    def get_position_status(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get detailed status of all positions.\n",
    "        Returns DataFrame with position information.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            r = positions.OpenPositions(accountID=self.account_id)\n",
    "            response = self.client.request(r)\n",
    "            positions_data = []\n",
    "            \n",
    "            for pos in response.get('positions', []):\n",
    "                pair = pos['instrument']\n",
    "                long_units = float(pos.get('long', {}).get('units', 0))\n",
    "                short_units = float(pos.get('short', {}).get('units', 0))\n",
    "                \n",
    "                positions_data.append({\n",
    "                    'pair': pair,\n",
    "                    'long_units': long_units,\n",
    "                    'short_units': short_units,\n",
    "                    'net_position': long_units + short_units,\n",
    "                    'timestamp': pd.Timestamp.now(tz='UTC')\n",
    "                })\n",
    "                \n",
    "            return pd.DataFrame(positions_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error getting position status: {str(e)}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "class SpreadTracker:\n",
    "    \"\"\"Tracks and analyzes spread costs by currency pair and trading session.\"\"\"\n",
    "    \n",
    "    def __init__(self, save_path: str = \"spread_history.parquet\"):\n",
    "        self.save_path = Path(save_path)\n",
    "        self.spreads = pd.DataFrame(columns=[\n",
    "            'timestamp', 'pair', 'ask', 'bid', 'spread',  # Changed from spread_pips to spread\n",
    "            'session', 'trade_type'\n",
    "        ])\n",
    "        self.load_history()\n",
    "        \n",
    "    def load_history(self):\n",
    "        \"\"\"Load existing spread history if available.\"\"\"\n",
    "        if self.save_path.exists():\n",
    "            self.spreads = pd.read_parquet(self.save_path)\n",
    "            \n",
    "    def get_current_prices(self, pair: str) -> Tuple[float, float]:\n",
    "        \"\"\"Get current bid/ask prices from OANDA.\"\"\"\n",
    "        params = {\n",
    "            \"count\": 1,\n",
    "            \"granularity\": \"S5\",  # 5-second candles for most recent price\n",
    "            \"price\": \"AB\"  # Ask and Bid prices\n",
    "        }\n",
    "        r = instruments.InstrumentsCandles(instrument=pair, params=params)\n",
    "        response = client.request(r)\n",
    "\n",
    "        \n",
    "        if not response.get('candles'):\n",
    "            raise ValueError(f\"No price data available for {pair}\")\n",
    "            \n",
    "        candle = response['candles'][0]\n",
    "\n",
    "        ask = float(candle['ask']['c'])\n",
    "        bid = float(candle['bid']['c'])\n",
    "        return ask, bid\n",
    "        \n",
    "    def record_spread(self, pair: str, trade_type: str) -> float:\n",
    "        \"\"\"\n",
    "        Record spread at time of trade execution.\n",
    "        \n",
    "        Args:\n",
    "            pair: Currency pair\n",
    "            trade_type: 'OPEN' or 'CLOSE'\n",
    "            \n",
    "        Returns:\n",
    "            float: Raw spread (ask - bid)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get current prices\n",
    "            ask, bid = self.get_current_prices(pair)\n",
    "            \n",
    "            # Calculate raw spread\n",
    "            spread = ask - bid\n",
    "            \n",
    "            # Determine current trading session\n",
    "            now = pd.Timestamp.now(tz='UTC')\n",
    "            session = self._get_trading_session(now)\n",
    "            \n",
    "            # Record spread\n",
    "            new_record = pd.DataFrame([{\n",
    "                'timestamp': now,\n",
    "                'pair': pair,\n",
    "                'ask': ask,\n",
    "                'bid': bid,\n",
    "                'spread': spread,  # Raw spread value\n",
    "                'session': session,\n",
    "                'trade_type': trade_type\n",
    "            }])\n",
    "            \n",
    "            self.spreads = pd.concat([self.spreads, new_record])\n",
    "            \n",
    "            # Save updated history\n",
    "            self.spreads.to_parquet(self.save_path)\n",
    "            \n",
    "            logger.info(f\"Recorded spread of {spread:.6f} for {pair} \"\n",
    "                    f\"during {session} session ({trade_type})\")\n",
    "            \n",
    "            return spread\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error recording spread for {pair}: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    def get_spread_statistics(self, pair: str = None, session: str = None) -> pd.DataFrame:\n",
    "        \"\"\"Get spread statistics by pair and/or session.\"\"\"\n",
    "        df = self.spreads\n",
    "        \n",
    "        if pair:\n",
    "            df = df[df['pair'] == pair]\n",
    "        if session:\n",
    "            df = df[df['session'] == session]\n",
    "            \n",
    "        # Simpler aggregation that won't result in NaN\n",
    "        stats = df.groupby(['pair', 'session']).agg({\n",
    "            'spread': ['mean', 'std', 'min', 'max', 'count'],\n",
    "            'timestamp': ['min', 'max']\n",
    "        }).round(6)  # Round to 6 decimal places for spreads\n",
    "        \n",
    "        return stats\n",
    "        \n",
    "    def _get_trading_session(self, timestamp: pd.Timestamp) -> str:\n",
    "        \"\"\"Determine current trading session.\"\"\"\n",
    "        hour = timestamp.hour\n",
    "        \n",
    "        # Convert to major session times\n",
    "        tokyo_hour = (hour + 9) % 24\n",
    "        ny_hour = (hour - 4) % 24\n",
    "        \n",
    "        if 9 <= tokyo_hour < 15:\n",
    "            return 'TOKYO'\n",
    "        elif 8 <= hour < 16:\n",
    "            return 'LONDON'\n",
    "        elif 8 <= ny_hour < 17:\n",
    "            return 'NEW_YORK'\n",
    "        else:\n",
    "            return 'OFF_HOURS'\n",
    "\n",
    "# Usage in TradingSystem class:\n",
    "# class TradingSystem:\n",
    "#     def __init__(self):\n",
    "#         # ... existing initialization ...\n",
    "#         self.spread_tracker = SpreadTracker()\n",
    "        \n",
    "#     def execute_trade(self, pair: str, current_position: str, new_position: str):\n",
    "#         \"\"\"Execute trade with spread tracking.\"\"\"\n",
    "#         try:\n",
    "#             # Record spread before closing position\n",
    "#             if current_position != 'NO_POSITION':\n",
    "#                 spread_close = self.spread_tracker.record_spread(pair, 'CLOSE')\n",
    "#                 print(f'Closing spread for {pair}: {spread_close:.1f} pips')\n",
    "                \n",
    "#             # Record spread before opening position    \n",
    "#             if new_position != 'NO_POSITION':\n",
    "#                 spread_open = self.spread_tracker.record_spread(pair, 'OPEN')\n",
    "#                 print(f'Opening spread for {pair}: {spread_open:.1f} pips')\n",
    "                \n",
    "#             # Execute trade as before...\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Error executing trade for {pair}: {str(e)}\")\n",
    "#             raise\n",
    "            \n",
    "#     def analyze_trading_costs(self) -> None:\n",
    "#         \"\"\"Analyze current trading costs.\"\"\"\n",
    "#         stats = self.spread_tracker.get_spread_statistics()\n",
    "#         print(\"\\nSpread Statistics by Pair and Session:\")\n",
    "#         print(stats)\n",
    "        \n",
    "#         # Calculate cost impact\n",
    "#         total_trades = len(self.spread_tracker.spreads)\n",
    "#         avg_spread_cost = stats['spread_pips']['mean'].mean()\n",
    "#         print(f\"\\nAverage spread cost across all pairs: {avg_spread_cost:.1f} pips\")\n",
    "#         print(f\"Total trades analyzed: {total_trades}\")\n",
    "\n",
    "# Trading pairs configuration with position sizes\n",
    "currency_pairs = {\n",
    "    'EUR_USD': 94_510.0,\n",
    "    'GBP_USD': 78_500.0,\n",
    "    'USD_JPY': 100_000.0,\n",
    "    'USD_CHF': 100_000.0,\n",
    "    'USD_CAD': 100_000.0,\n",
    "    'AUD_USD': 153_000.0,\n",
    "    'NZD_USD': 171_430.0,\n",
    "\n",
    "    # Cross Pairs\n",
    "    'EUR_GBP': 94_510,\n",
    "    'EUR_CHF': 94_510,\n",
    "    'EUR_JPY': 94_510,\n",
    "    'EUR_CAD': 94_510,\n",
    "    'GBP_CHF': 78_500.0,\n",
    "    'GBP_JPY': 78_500.0,\n",
    "    'CHF_JPY': 88_100.0,\n",
    "    'AUD_JPY': 153_000.0,\n",
    "    'NZD_JPY': 171_430.0,\n",
    "\n",
    "    # Precious Metals\n",
    "    'XAU_USD': 38.0,  \n",
    "    'XAG_USD': 3_266  \n",
    "\n",
    "}\n",
    "\n",
    "def get_current_time():\n",
    "    return datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "class FastDataManager:\n",
    "    \"\"\"High-performance data manager optimized for low-latency trading.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        base_storage_path: str,\n",
    "        max_history_size: int = 10000\n",
    "    ):\n",
    "        self.base_storage_path = Path(base_storage_path)\n",
    "        self.max_history_size = max_history_size\n",
    "        self.training_features = [\n",
    "            'close', 'sma_20', 'sma_50', 'rsi', 'macd', \n",
    "            'macd_signal', 'macd_hist', 'bb_upper', 'bb_middle', \n",
    "            'bb_lower', 'bb_bandwidth', 'bb_percent', 'atr', \n",
    "            'plus_di', 'minus_di', 'adx', 'senkou_span_a', \n",
    "            'senkou_span_b', 'tenkan_sen', 'kijun_sen'\n",
    "        ]\n",
    "        \n",
    "        # Storage for different data types\n",
    "        self.raw_data: Dict[str, pd.DataFrame] = {}\n",
    "        self.normalized_data: Dict[str, pd.DataFrame] = {}\n",
    "        \n",
    "        # Thread safety\n",
    "        self.data_lock = threading.Lock()\n",
    "        self.save_queue = Queue()\n",
    "        \n",
    "        # Initialize components\n",
    "        self.indicator_manager = IndicatorManager()\n",
    "        self.data_processor = DataPreprocessor()\n",
    "        \n",
    "        # Start save worker\n",
    "        self.save_worker = threading.Thread(\n",
    "            target=self._parquet_save_worker,\n",
    "            daemon=True,\n",
    "            name=\"ParquetSaveWorker\"\n",
    "        )\n",
    "        self.save_worker.start()\n",
    "    \n",
    "    def fetch_missing_candles(self, pair: str, last_timestamp: pd.Timestamp) -> pd.DataFrame:\n",
    "        \"\"\"Fetch new candles from OANDA.\"\"\"\n",
    "        print(f\"Fetching missing candles for {pair}...\")\n",
    "        print(f'Fetch missing candles for {pair} - time {get_current_time()}')\n",
    "        params = {\n",
    "            \"from\": last_timestamp.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            \"granularity\": \"M5\",\n",
    "            \"price\": \"M\"\n",
    "        }\n",
    "        \n",
    "        r = instruments.InstrumentsCandles(instrument=pair, params=params)\n",
    "        response = client.request(r)\n",
    "        candles = response.get('candles', [])\n",
    "        \n",
    "        if not candles:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        df_list = [{\n",
    "            'timestamp': pd.to_datetime(candle['time'], utc=True),\n",
    "            'open': float(candle['mid']['o']),\n",
    "            'high': float(candle['mid']['h']),\n",
    "            'low': float(candle['mid']['l']),\n",
    "            'close': float(candle['mid']['c']),\n",
    "            # 'volume': int(candle['volume'])\n",
    "        } for candle in candles if candle['complete']]\n",
    "        \n",
    "        if not df_list:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        df = pd.DataFrame(df_list)\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "        # df.index = df.index.tz_localize('UTC')\n",
    "        print(f\"Fetched {len(df)} candles for {pair}. at time {get_current_time()}\")\n",
    "        print(df)\n",
    "        return df\n",
    "\n",
    "    def initialize_pair(self, pair: str) -> bool:\n",
    "        \"\"\"Initialize data for a pair.\"\"\"\n",
    "        try:\n",
    "            parquet_path = self.base_storage_path / f\"{pair}_5T_indics_1H_not_norm.parquet\"\n",
    "            df = pd.read_parquet(parquet_path)\n",
    "            \n",
    "            if df.index.tz is None:\n",
    "                df.index = df.index.tz_localize('UTC')\n",
    "            #! disable the logic to fetch only last 1000 datapoints for now (1000 might not be enough and check if this changes the values and confuse agent)      \n",
    "            # if len(df) > self.max_history_size:\n",
    "            #     df = df.iloc[-self.max_history_size:]\n",
    "            \n",
    "            with self.data_lock:\n",
    "                self.raw_data[pair] = df\n",
    "                self.normalized_data[pair] = self.data_processor.normalize_simple(df)\n",
    "                \n",
    "            # logger.info(f\"Initialized data for {pair}, loaded {len(df)} candles\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize {pair}: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def update_pair_data(self, pair: str) -> bool:\n",
    "        \"\"\"Update data for a pair with safer data concatenation.\"\"\"\n",
    "        print(f\"Updating data for {pair} - time {get_current_time()}\")\n",
    "\n",
    "        try:\n",
    "            with self.data_lock:\n",
    "                if pair not in self.raw_data:\n",
    "                    raise KeyError(f\"Pair {pair} not initialized\")\n",
    "                    \n",
    "                df = self.raw_data[pair]\n",
    "                last_timestamp = df.index[-1]\n",
    "                print(f\"Last timestamp for {pair}: {last_timestamp}\")\n",
    "\n",
    "            current_time = pd.Timestamp.now(tz='UTC')\n",
    "            \n",
    "            if current_time - last_timestamp >= timedelta(minutes=5):\n",
    "                print(f\"Fetching new data for {pair}\")\n",
    "                new_data = self.fetch_missing_candles(pair, last_timestamp)\n",
    "                \n",
    "                if not new_data.empty:\n",
    "                    with self.data_lock:\n",
    "                        # Ensure indices are datetime and timezone-aware\n",
    "                        if df.index.tz is None:\n",
    "                            df.index = df.index.tz_localize('UTC')\n",
    "                        if new_data.index.tz is None:\n",
    "                            new_data.index = new_data.index.tz_localize('UTC')\n",
    "                        \n",
    "                        # Combine old and new data\n",
    "                        combined_df = pd.concat([df, new_data])\n",
    "                        \n",
    "                        # Remove any duplicates, keeping the latest version\n",
    "                        combined_df = combined_df[~combined_df.index.duplicated(keep='last')]\n",
    "                        \n",
    "                        # Sort by timestamp\n",
    "                        combined_df.sort_index(inplace=True)\n",
    "                        \n",
    "                        # Calculate indicators on the full dataset\n",
    "                        try:\n",
    "                            combined_df_with_indicators = self.indicator_manager.calculate_indicators(combined_df)\n",
    "                            print(f\"Successfully calculated indicators for {pair}\")\n",
    "                            \n",
    "                            # Update the stored data\n",
    "                            self.raw_data[pair] = combined_df_with_indicators\n",
    "                            \n",
    "                            # Update normalized data\n",
    "                            self.normalized_data[pair] = self.data_processor.normalize_simple(\n",
    "                                combined_df_with_indicators\n",
    "                            )\n",
    "                            \n",
    "                            # Queue the save operation\n",
    "                            try:\n",
    "                                self.save_queue.put((pair, combined_df_with_indicators))\n",
    "                                print(f\"Data queued for saving for {pair}\")\n",
    "                            except Exception as e:\n",
    "                                logger.error(f\"Error queuing save operation for {pair}: {str(e)}\")\n",
    "                                \n",
    "                            return True\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Error calculating indicators for {pair}: {str(e)}\")\n",
    "                            raise\n",
    "                            \n",
    "                else:\n",
    "                    logger.info(f\"No new data available for {pair}\")\n",
    "                    return False\n",
    "            \n",
    "            return False\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error updating data for {pair}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_prediction_data(self, pair: str, sequence_length: int, current_position: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get normalized data sequence for prediction.\n",
    "        Ensures feature consistency with training environment.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.data_lock:\n",
    "                if pair not in self.normalized_data:\n",
    "                    raise KeyError(f\"No data available for {pair}\")\n",
    "                \n",
    "                df = self.normalized_data[pair]\n",
    "                \n",
    "                # Define the exact features used in training\n",
    "                training_features = [\n",
    "                    'close', 'sma_20', 'sma_50', 'rsi', 'macd', \n",
    "                    'macd_signal', 'macd_hist', 'bb_upper', 'bb_middle', \n",
    "                    'bb_lower', 'bb_bandwidth', 'bb_percent', 'atr', \n",
    "                    'plus_di', 'minus_di', 'adx', 'senkou_span_a', \n",
    "                    'senkou_span_b', 'tenkan_sen', 'kijun_sen'\n",
    "                ]\n",
    "                \n",
    "                # Select only the features used in training\n",
    "                df_features = df[training_features]\n",
    "                \n",
    "                # Get last sequence_length rows\n",
    "                sequence = df_features.iloc[-sequence_length:].values\n",
    "                sequence_transposed = sequence.T\n",
    "                market_features = sequence_transposed.flatten()\n",
    "                \n",
    "                # Add position information\n",
    "                position_info = np.array([current_position])\n",
    "                observation = np.concatenate([market_features, position_info])\n",
    "                \n",
    "                # Validate shape\n",
    "                expected_size = sequence_length * len(training_features) + 1\n",
    "                if observation.shape[0] != expected_size:\n",
    "                    raise ValueError(\n",
    "                        f\"Observation shape mismatch: got {observation.shape[0]}, \"\n",
    "                        f\"expected {expected_size}\"\n",
    "                    )\n",
    "                \n",
    "                # # Debug information\n",
    "                # logger.debug(f\"Observation construction for {pair}:\")\n",
    "                # logger.debug(f\"Number of features: {len(training_features)}\")\n",
    "                # logger.debug(f\"Sequence shape: {sequence.shape}\")\n",
    "                # logger.debug(f\"Final shape: {observation.shape}\")\n",
    "                \n",
    "                return observation.astype(np.float32)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error constructing prediction data for {pair}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _parquet_save_worker(self) -> None:\n",
    "        \"\"\"Background worker for parquet saves with improved error handling.\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                pair, df = self.save_queue.get()\n",
    "                if pair is None:\n",
    "                    break\n",
    "                    \n",
    "                parquet_path = self.base_storage_path / f\"{pair}_5T_indics_1H_not_norm.parquet\"\n",
    "                \n",
    "                # Create a backup of the existing file\n",
    "                if parquet_path.exists():\n",
    "                    backup_path = parquet_path.with_suffix('.parquet.backup')\n",
    "                    parquet_path.rename(backup_path)\n",
    "                \n",
    "                try:\n",
    "                    # Save the new data\n",
    "                    df.to_parquet(parquet_path)\n",
    "                    \n",
    "                    # If save successful, remove backup\n",
    "                    if backup_path.exists():\n",
    "                        backup_path.unlink()\n",
    "                        \n",
    "                    logger.info(f\"Successfully saved data for {pair}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # If save fails, restore from backup\n",
    "                    if backup_path.exists():\n",
    "                        backup_path.rename(parquet_path)\n",
    "                    logger.error(f\"Error saving data for {pair}, restored from backup: {str(e)}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in save worker: {str(e)}\")\n",
    "            finally:\n",
    "                self.save_queue.task_done()\n",
    "\n",
    "\n",
    "class TradingSystem:\n",
    "    \"\"\"Main trading system coordination.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_manager = None\n",
    "        self.models = {}\n",
    "        self.positions = {}\n",
    "        self.positions_lock = threading.Lock()\n",
    "        self.position_entry_prices = {}\n",
    "        self.position_entry_times = {}\n",
    "        self.position_entry_indicators = {}\n",
    "        self.position_entry_spreads = {}\n",
    "        self.start_time = datetime.now(timezone.utc)\n",
    "\n",
    "    def position_to_float(self, position_type: str) -> float:\n",
    "        \"\"\"Convert position type to float representation.\"\"\"\n",
    "        position_map = {\n",
    "            'LONG': 1.0,\n",
    "            'SHORT': -1.0,\n",
    "            'NO_POSITION': 0.0\n",
    "        }\n",
    "        return position_map.get(position_type, 0.0)\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"Initialize the trading system.\"\"\"\n",
    "        logger.info(\"Initializing trading system...\")\n",
    "        \n",
    "        # Initialize data manager\n",
    "        self.data_manager = FastDataManager(\n",
    "            base_storage_path=\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/best_dataframes_not_norm/to_test_deploy\"\n",
    "        )\n",
    "        \n",
    "        # Load models and initialize data for each pair\n",
    "        for pair in currency_pairs:\n",
    "            try:\n",
    "                if not self.data_manager.initialize_pair(pair):\n",
    "                    continue\n",
    "                    \n",
    "                model_path = f'/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/best_dataframes_true_cost/models_and_vecs/{pair}_best_model'\n",
    "                env_path = f'/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/best_dataframes_true_cost/models_and_vecs/{pair}_vec_normalize.pkl'\n",
    "                \n",
    "                # Create environment for loading model\n",
    "                vec_env = DummyVecEnv([lambda: ForexTradingEnv(\n",
    "                    self.data_manager.raw_data[pair], pair\n",
    "                )])\n",
    "                \n",
    "                # Load environment normalization\n",
    "                env = VecNormalize.load(env_path, vec_env)\n",
    "                env.training = False\n",
    "                env.norm_reward = False\n",
    "                \n",
    "                # Load the model\n",
    "                model = PPO.load(model_path, env=env)\n",
    "                self.models[pair] = model\n",
    "                # print(f\"Loaded model for {pair}\")\n",
    "                # logger.info(f\"Models loaded: {list(self.models.keys())}\")\n",
    "                # logger.info(f\"Initialized model for {pair}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error initializing {pair}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Sync initial positions\n",
    "        self.sync_positions()\n",
    "        # print(f\"Initialized done\")\n",
    "        # print(f'self.models after init at time {get_current_time()}: {self.models}')\n",
    "        \n",
    "    def _make_prediction(self, pair: str, observation: np.ndarray) -> str:\n",
    "        \"\"\"\n",
    "        Make a prediction using the loaded model.\n",
    "        Returns position type ('NO_POSITION', 'LONG', or 'SHORT').\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if pair not in self.models:\n",
    "                raise KeyError(f\"No model loaded for {pair}\")\n",
    "\n",
    "            # Reshape observation for model input\n",
    "            model_input = observation.reshape(1, -1)\n",
    "            \n",
    "            # Get model's expected shape\n",
    "            expected_shape = self.models[pair].policy.observation_space.shape[0]\n",
    "            actual_shape = observation.shape[0]\n",
    "            \n",
    "            if actual_shape != expected_shape:\n",
    "                raise ValueError(\n",
    "                    f\"Observation shape mismatch for {pair}: \"\n",
    "                    f\"expected {expected_shape}, got {actual_shape}\"\n",
    "                )\n",
    "            \n",
    "            # Get prediction\n",
    "            action, _ = self.models[pair].predict(model_input, deterministic=True)\n",
    "            \n",
    "            # Map action to position type\n",
    "            action_map = {0: 'NO_POSITION', 1: 'LONG', 2: 'SHORT'}\n",
    "            return action_map[action[0]]\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error making prediction for {pair}: {str(e)}\")\n",
    "            # Return current position on error to avoid unwanted changes\n",
    "            return self.positions.get(pair, 'NO_POSITION')\n",
    "        \n",
    "    def sync_positions(self):\n",
    "        \"\"\"Synchronize positions with broker.\"\"\"\n",
    "        try:\n",
    "            r = positions.OpenPositions(accountID=OANDA_ACCOUNT_ID)\n",
    "            response = client.request(r)\n",
    "            print(f'sync_positions response: {response}')\n",
    "            \n",
    "            with self.positions_lock:\n",
    "                self.positions.clear()\n",
    "                for pos in response.get('positions', []):\n",
    "                    pair = pos['instrument']\n",
    "                    if pair in currency_pairs:\n",
    "                        if float(pos.get('long', {}).get('units', 0)) > 0:\n",
    "                            self.positions[pair] = 'LONG'\n",
    "                        elif float(pos.get('short', {}).get('units', 0)) < 0:\n",
    "                            self.positions[pair] = 'SHORT'\n",
    "                        else:\n",
    "                            self.positions[pair] = 'NO_POSITION'\n",
    "            print(f'self.postions after sync {self.positions} at time {get_current_time()}')            \n",
    "            logger.info(\"Positions synchronized\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error syncing positions: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "        \n",
    "    def execute_trade(self, pair: str, current_position: str, new_position: str):\n",
    "        \"\"\"Execute a trade.\"\"\"\n",
    "        print(f'execute_trade called for {pair} with current_position {current_position} and new_position {new_position} at time {get_current_time()}')\n",
    "        try:\n",
    "            # Close existing position if any\n",
    "            if current_position != 'NO_POSITION':\n",
    "                print(f'Closing existing position for {pair}')\n",
    "   \n",
    "                self.close_position(pair, current_position)\n",
    "            \n",
    "            # Open new position if not moving to neutral\n",
    "            if new_position != 'NO_POSITION':\n",
    "                print(f'Opening new position for {pair}')\n",
    "          \n",
    "                self.open_position(pair, new_position)\n",
    "            \n",
    "            # Update position storage\n",
    "            with self.positions_lock:\n",
    "                self.positions[pair] = new_position\n",
    "                \n",
    "            logger.info(f\"Executed trade for {pair}: {current_position} -> {new_position}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error executing trade for {pair}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def open_position(self, pair: str, position_type: str):\n",
    "        print(f'open_position called for {pair} with position_type {position_type}')\n",
    "        \"\"\"Open a new position.\"\"\"\n",
    "        units = currency_pairs[pair]\n",
    "        if position_type == 'SHORT':\n",
    "            units = -units\n",
    "            \n",
    "        data = {\n",
    "            \"order\": {\n",
    "                \"instrument\": pair,\n",
    "                \"units\": str(units),\n",
    "                \"type\": \"MARKET\",\n",
    "                \"positionFill\": \"DEFAULT\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        r = orders.OrderCreate(accountID=OANDA_ACCOUNT_ID, data=data)\n",
    "        client.request(r)\n",
    "        print(f'open_position response: {r} at time {get_current_time()}')\n",
    "\n",
    "    def close_position(self, pair: str, position_type: str):\n",
    "        print(f'close_position called for {pair} with position_type {position_type}')\n",
    "        \"\"\"Close an existing position.\"\"\"\n",
    "        data = {\n",
    "            \"longUnits\": \"ALL\"\n",
    "        } if position_type == 'LONG' else {\n",
    "            \"shortUnits\": \"ALL\"\n",
    "        }\n",
    "        \n",
    "        r = positions.PositionClose(\n",
    "            accountID=OANDA_ACCOUNT_ID,\n",
    "            instrument=pair,\n",
    "            data=data\n",
    "        )\n",
    "        client.request(r)\n",
    "        print(f'close_position response: {r} at time {get_current_time()}')\n",
    "\n",
    "    def trading_cycle(self):\n",
    "        \"\"\"Execute one trading cycle.\"\"\"\n",
    "        logger.info(\"Starting trading cycle\")\n",
    "        print(\"Available models:\", list(self.models.keys()))\n",
    "\n",
    "        for pair in currency_pairs:\n",
    "            try:\n",
    "                if pair not in self.models:\n",
    "                    logger.error(f\"No model loaded for {pair}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Update market data\n",
    "                if self.data_manager.update_pair_data(pair):\n",
    "                    # Get current position\n",
    "                    with self.positions_lock:\n",
    "                        current_position_type = self.positions.get(pair, 'NO_POSITION')\n",
    "                        print(f'current_position_type {current_position_type}')\n",
    "                    \n",
    "                    # Convert position to float for observation\n",
    "                    current_position_float = self.position_to_float(current_position_type)\n",
    "                    print(f'current_position_float {current_position_float} for pair {pair} at time {get_current_time()}')\n",
    "\n",
    "                    # Get prediction data\n",
    "                    observation = self.data_manager.get_prediction_data(\n",
    "                        pair=pair,\n",
    "                        sequence_length=5,\n",
    "                        current_position=current_position_float\n",
    "                    )\n",
    "\n",
    "                    # Get model prediction\n",
    "                    action_name = self._make_prediction(pair, observation)\n",
    "                    print(f'action_name {action_name} for pair {pair}')\n",
    "\n",
    "                    # Execute trade if position change needed\n",
    "                    if current_position_type != action_name:\n",
    "                        print(f'execute_trade called for {pair} with current_position_type {current_position_type} and action_name {action_name}')\n",
    "                        self.execute_trade(pair, current_position_type, action_name)\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in trading cycle for {pair}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run the trading system.\"\"\"\n",
    "        try:\n",
    "            self.initialize()\n",
    "            print('def run _ self.initialize() complete')\n",
    "            \n",
    "            scheduler = BackgroundScheduler()\n",
    "            scheduler.add_job(\n",
    "                self.trading_cycle,\n",
    "                'cron',\n",
    "                minute='*/5',\n",
    "                second=0\n",
    "            )\n",
    "            scheduler.start()\n",
    "            \n",
    "            logger.info(\"Trading system started\")\n",
    "            \n",
    "            while True:\n",
    "                time.sleep(60)\n",
    "                \n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            logger.info(\"Shutting down trading system...\")\n",
    "            scheduler.shutdown()\n",
    "            self.data_manager.shutdown()\n",
    "            logger.info(\"Trading system shutdown complete\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fatal error in trading system: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler('trading_system.log'),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    logger = logging.getLogger('trading_system')\n",
    "    \n",
    "    # Start trading system\n",
    "    logger.info(\"Starting trading system...\")\n",
    "    trading_system = TradingSystem()\n",
    "    trading_system.run()\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    logger.info(\"Received shutdown signal. Initiating graceful shutdown...\")\n",
    "    trading_system.data_manager.shutdown()\n",
    "    logger.info(\"Trading system shutdown complete.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Fatal error: {str(e)}\", exc_info=True)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Optional, Tuple, List\n",
    "from pathlib import Path\n",
    "import threading\n",
    "from queue import Queue\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pytz\n",
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "\n",
    "# Trading components\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "\n",
    "# OANDA components\n",
    "from oandapyV20 import API\n",
    "import oandapyV20.endpoints.positions as positions\n",
    "import oandapyV20.endpoints.orders as orders\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "import oandapyV20.endpoints.trades as trades\n",
    "\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import local components\n",
    "from trading.environments.forex_env2_flat import ForexTradingEnv\n",
    "from data_management.preprocessor import DataPreprocessor\n",
    "from data_management.indicator_manager import IndicatorManager\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# OANDA Configuration\n",
    "OANDA_API_KEY = '9317ace4596d61e3e98b1a53b2342483-45d3ad4084c80b111727a9fada9ef0ff'\n",
    "OANDA_ACCOUNT_ID = '101-004-30348600-001' #running account\n",
    "# OANDA_ACCOUNT_ID = '101-004-30348600-002'\n",
    "OANDA_ENV = 'practice'\n",
    "\n",
    "# Initialize OANDA client\n",
    "client = API(access_token=OANDA_API_KEY, environment=OANDA_ENV)\n",
    "\n",
    "def fetch_missing_candles( pair: str, last_timestamp: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"Fetch new candles from OANDA.\"\"\"\n",
    "\n",
    "    params = {\n",
    "        \"from\": last_timestamp.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "        \"granularity\": \"M5\",\n",
    "        \"price\": \"M\"\n",
    "    }\n",
    "    \n",
    "    r = instruments.InstrumentsCandles(instrument=pair, params=params)\n",
    "    response = client.request(r)\n",
    "    candles = response.get('candles', [])\n",
    "    print('CANDLE PRINT')\n",
    "    print(candles)\n",
    "    print('CANDLE PRINT')\n",
    "    \n",
    "    if not candles:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    df_list = [{\n",
    "        'timestamp': pd.to_datetime(candle['time'], utc=True),\n",
    "        'open': float(candle['mid']['o']),\n",
    "        'high': float(candle['mid']['h']),\n",
    "        'low': float(candle['mid']['l']),\n",
    "        'close': float(candle['mid']['c']),\n",
    "        # 'volume': int(candle['volume'])\n",
    "    } for candle in candles if candle['complete']]\n",
    "    \n",
    "    if not df_list:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    df = pd.DataFrame(df_list)\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    # df.index = df.index.tz_localize('UTC')\n",
    "  \n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair = 'EUR_USD'\n",
    "# base_storage_path=\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/best_dataframes_not_norm/to_test_deploy\"\n",
    "# currency = f\"{pair}_5T_indics_1H_not_norm.parquet\"\n",
    "# path = os.path.join(base_storage_path, currency)\n",
    "# df = pd.read_parquet(path)\n",
    "# # df\n",
    "\n",
    "# last_timestamp = df.index[-1]\n",
    "# new_timestamp = pd.Timestamp(last_timestamp) + pd.Timedelta(hours=11,minutes=30)\n",
    "# new_timestamp\n",
    "# candles = fetch_missing_candles(pair=pair,last_timestamp=new_timestamp)\n",
    "# candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import oandapyV20\n",
    "# import oandapyV20.endpoints.accounts as accounts\n",
    "# OANDA_API_KEY = '9317ace4596d61e3e98b1a53b2342483-45d3ad4084c80b111727a9fada9ef0ff'\n",
    "\n",
    "# api = oandapyV20.API(access_token=OANDA_API_KEY)\n",
    "# r = accounts.AccountList()\n",
    "# api.request(r)\n",
    "# print(r.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair = 'XAU_USD'\n",
    "# spread_tracker = SpreadTracker()\n",
    "# spread_close = spread_tracker.record_spread(pair, 'CLOSE')\n",
    "# stats = spread_tracker.get_spread_statistics()\n",
    "# stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Keep all your existing methods (sync_positions, execute_trade, etc.)\n",
    "    # They remain unchanged\n",
    "\n",
    "# class TradingSystem:\n",
    "#     \"\"\"Main trading system coordination.\"\"\"\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         self.data_manager = None\n",
    "#         self.models = {}\n",
    "#         self.positions = {}\n",
    "#         self.positions_lock = threading.Lock()\n",
    "#         self.performance_tracker = PerformanceTracker(\n",
    "#             base_path=Path(\"./trading_performance\")\n",
    "#         )\n",
    "\n",
    "\n",
    "#     def position_to_float(self, position_type: str) -> float:\n",
    "#         \"\"\"Convert position type to float representation.\"\"\"\n",
    "#         position_map = {\n",
    "#             'LONG': 1.0,\n",
    "#             'SHORT': -1.0,\n",
    "#             'NO_POSITION': 0.0\n",
    "#         }\n",
    "#         return position_map.get(position_type, 0.0)\n",
    "        \n",
    "#     def initialize(self):\n",
    "#         \"\"\"Initialize the trading system.\"\"\"\n",
    "#         logger.info(\"Initializing trading system...\")\n",
    "        \n",
    "#         # Initialize data manager\n",
    "#         self.data_manager = FastDataManager(\n",
    "#             base_storage_path=\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/best_dataframes_not_norm/to_test_deploy\"\n",
    "#         )\n",
    "        \n",
    "#         # Load models and initialize data for each pair\n",
    "#         for pair in currency_pairs:\n",
    "#             try:\n",
    "#                 if not self.data_manager.initialize_pair(pair):\n",
    "#                     continue\n",
    "                    \n",
    "#                 model_path = f'/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/best_dataframes_true_cost/models_and_vecs/{pair}_best_model'\n",
    "#                 env_path = f'/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/best_dataframes_true_cost/models_and_vecs/{pair}_vec_normalize.pkl'\n",
    "                \n",
    "#                 vec_env = DummyVecEnv([lambda: ForexTradingEnv(\n",
    "#                     self.data_manager.raw_data[pair], pair\n",
    "#                 )])\n",
    "                \n",
    "#                 env = VecNormalize.load(env_path, vec_env)\n",
    "#                 env.training = False\n",
    "#                 env.norm_reward = False\n",
    "                \n",
    "#                 model = PPO.load(model_path, env=env)\n",
    "#                 self.models[pair] = model\n",
    "#                 print(f\"Loaded model for {pair}\")\n",
    "#                 logger.info(f\"Models loaded: {list(self.models.keys())}\")\n",
    "\n",
    "                \n",
    "#                 logger.info(f\"Initialized model for {pair}\")\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 logger.error(f\"Error initializing {pair}: {str(e)}\")\n",
    "#                 continue\n",
    "        \n",
    "#         # Sync initial positions\n",
    "#         self.sync_positions()\n",
    "#         print(f\"Initialized done\")\n",
    "#         print(f'self.models after init at time {get_current_time()}: {self.models}')\n",
    "        \n",
    "#     def sync_positions(self):\n",
    "#         \"\"\"Synchronize positions with broker.\"\"\"\n",
    "#         try:\n",
    "#             r = positions.OpenPositions(accountID=OANDA_ACCOUNT_ID)\n",
    "#             response = client.request(r)\n",
    "#             print(f'sync_positions response: {response}')\n",
    "            \n",
    "#             with self.positions_lock:\n",
    "#                 self.positions.clear()\n",
    "#                 for pos in response.get('positions', []):\n",
    "#                     pair = pos['instrument']\n",
    "#                     if pair in currency_pairs:\n",
    "#                         if float(pos.get('long', {}).get('units', 0)) > 0:\n",
    "#                             self.positions[pair] = 'LONG'\n",
    "#                         elif float(pos.get('short', {}).get('units', 0)) < 0:\n",
    "#                             self.positions[pair] = 'SHORT'\n",
    "#                         else:\n",
    "#                             self.positions[pair] = 'NO_POSITION'\n",
    "#             print(f'self.postions after sync {self.positions} at time {get_current_time()}')            \n",
    "#             logger.info(\"Positions synchronized\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Error syncing positions: {str(e)}\")\n",
    "#             raise\n",
    "\n",
    "#     def execute_trade(self, pair: str, current_position: str, new_position: str):\n",
    "#         \"\"\"Execute a trade.\"\"\"\n",
    "#         print(f'execute_trade called for {pair} with current_position {current_position} and new_position {new_position} at time {get_current_time()}')\n",
    "#         try:\n",
    "#             # Close existing position if any\n",
    "#             if current_position != 'NO_POSITION':\n",
    "#                 print(f'Closing existing position for {pair}')\n",
    "#                 #! Trading disabled for now\n",
    "#                 # self.close_position(pair, current_position)\n",
    "            \n",
    "#             # Open new position if not moving to neutral\n",
    "#             if new_position != 'NO_POSITION':\n",
    "#                 print(f'Opening new position for {pair}')\n",
    "#                 #! Trading disabled for now\n",
    "#                 # self.open_position(pair, new_position)\n",
    "            \n",
    "#             # Update position storage\n",
    "#             with self.positions_lock:\n",
    "#                 self.positions[pair] = new_position\n",
    "                \n",
    "#             logger.info(f\"Executed trade for {pair}: {current_position} -> {new_position}\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Error executing trade for {pair}: {str(e)}\")\n",
    "#             raise\n",
    "\n",
    "#     def open_position(self, pair: str, position_type: str):\n",
    "#         print(f'open_position called for {pair} with position_type {position_type}')\n",
    "#         \"\"\"Open a new position.\"\"\"\n",
    "#         units = currency_pairs[pair]\n",
    "#         if position_type == 'SHORT':\n",
    "#             units = -units\n",
    "            \n",
    "#         data = {\n",
    "#             \"order\": {\n",
    "#                 \"instrument\": pair,\n",
    "#                 \"units\": str(units),\n",
    "#                 \"type\": \"MARKET\",\n",
    "#                 \"positionFill\": \"DEFAULT\"\n",
    "#             }\n",
    "#         }\n",
    "        \n",
    "#         r = orders.OrderCreate(accountID=OANDA_ACCOUNT_ID, data=data)\n",
    "#         client.request(r)\n",
    "#         print(f'open_position response: {r} at time {get_current_time()}')\n",
    "\n",
    "#     def close_position(self, pair: str, position_type: str):\n",
    "#         print(f'close_position called for {pair} with position_type {position_type}')\n",
    "#         \"\"\"Close an existing position.\"\"\"\n",
    "#         data = {\n",
    "#             \"longUnits\": \"ALL\"\n",
    "#         } if position_type == 'LONG' else {\n",
    "#             \"shortUnits\": \"ALL\"\n",
    "#         }\n",
    "        \n",
    "#         r = positions.PositionClose(\n",
    "#             accountID=OANDA_ACCOUNT_ID,\n",
    "#             instrument=pair,\n",
    "#             data=data\n",
    "#         )\n",
    "#         client.request(r)\n",
    "#         print(f'close_position response: {r} at time {get_current_time()}')\n",
    "\n",
    "#     def trading_cycle(self):\n",
    "#         print(f'!!! trading_cycle called')\n",
    "#         print(f\"Available models: {list(self.models.keys())}\")\n",
    "\n",
    "#         \"\"\"Execute one trading cycle with updated observation handling.\"\"\"\n",
    "#         logger.info(\"Starting trading cycle\")\n",
    "        \n",
    "#         for pair in currency_pairs:\n",
    "#             try:\n",
    "#                 if pair not in self.models:\n",
    "#                     logger.error(f\"No model loaded for {pair}, skipping.\")\n",
    "#                     continue\n",
    "#                 if self.data_manager.update_pair_data(pair):\n",
    "#                     # Get current position\n",
    "#                     with self.positions_lock:\n",
    "#                         current_position_type = self.positions.get(pair, 'NO_POSITION')\n",
    "#                         print(f'current_position_type {current_position_type}')\n",
    "#                     current_position_float = self.position_to_float(current_position_type)\n",
    "#                     print(f'current_position_float {current_position_float} for pair {pair} at time {get_current_time()}')\n",
    "                    \n",
    "#                     # Get prediction data with current position\n",
    "#                     sequence = self.data_manager.get_prediction_data(\n",
    "#                         pair=pair,\n",
    "#                         sequence_length=5,\n",
    "#                         current_position=current_position_float\n",
    "#                     )\n",
    "                    \n",
    "#                     # Reshape for model\n",
    "#                     obs_array = sequence.reshape((1, -1))\n",
    "                    \n",
    "#                     # Get model prediction\n",
    "#                     model = self.models[pair]\n",
    "#                     obs_array = model.env.normalize_obs(obs_array)\n",
    "#                     action, _ = model.predict(obs_array, deterministic=True)\n",
    "                    \n",
    "#                     # Convert action to position type\n",
    "#                     action_name = {0: 'NO_POSITION', 1: 'LONG', 2: 'SHORT'}[action[0]]\n",
    "#                     print(f'action_name {action_name} for pair {pair}')\n",
    "                    \n",
    "#                     # Execute trade if position change needed\n",
    "#                     if current_position_type != action_name:\n",
    "#                         print(f'execute_trade called for {pair} with current_position_type {current_position_type} and action_name {action_name}')\n",
    "#                         self.execute_trade(pair, current_position_type, action_name)\n",
    "                        \n",
    "#                         # Update position tracking\n",
    "#                         with self.positions_lock:\n",
    "#                             self.positions[pair] = action_name\n",
    "            \n",
    "#             except Exception as e:\n",
    "#                 logger.error(f\"Error in trading cycle for {pair}: {str(e)}\")\n",
    "#                 continue\n",
    "\n",
    "#     def run(self):\n",
    "#         \"\"\"Run the trading system.\"\"\"\n",
    "#         try:\n",
    "#             self.initialize()\n",
    "#             print('def run _ self.initialize() complete')\n",
    "            \n",
    "#             scheduler = BackgroundScheduler()\n",
    "#             scheduler.add_job(\n",
    "#                 self.trading_cycle,\n",
    "#                 'cron',\n",
    "#                 minute='*/5',\n",
    "#                 second=0\n",
    "#             )\n",
    "#             scheduler.start()\n",
    "            \n",
    "#             logger.info(\"Trading system started\")\n",
    "            \n",
    "#             while True:\n",
    "#                 time.sleep(60)\n",
    "                \n",
    "#         except (KeyboardInterrupt, SystemExit):\n",
    "#             logger.info(\"Shutting down trading system...\")\n",
    "#             scheduler.shutdown()\n",
    "#             self.data_manager.shutdown()\n",
    "#             logger.info(\"Trading system shutdown complete\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Fatal error in trading system: {str(e)}\")\n",
    "#             raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Optional, Tuple, List\n",
    "from pathlib import Path\n",
    "import threading\n",
    "from queue import Queue\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pytz\n",
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "\n",
    "# Trading components\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "\n",
    "# OANDA components\n",
    "from oandapyV20 import API\n",
    "import oandapyV20.endpoints.positions as positions\n",
    "import oandapyV20.endpoints.orders as orders\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "import oandapyV20.endpoints.trades as trades\n",
    "\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import local components\n",
    "from trading.environments.forex_env2_flat import ForexTradingEnv\n",
    "from data_management.preprocessor import DataPreprocessor\n",
    "from data_management.indicator_manager import IndicatorManager\n",
    "\n",
    "\n",
    "class FastDataManager:\n",
    "    \"\"\"High-performance data manager optimized for low-latency trading.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        base_storage_path: str,\n",
    "        max_history_size: int = 10000\n",
    "    ):\n",
    "        self.base_storage_path = Path(base_storage_path)\n",
    "        self.max_history_size = max_history_size\n",
    "        self.training_features = [\n",
    "            'close', 'sma_20', 'sma_50', 'rsi', 'macd', \n",
    "            'macd_signal', 'macd_hist', 'bb_upper', 'bb_middle', \n",
    "            'bb_lower', 'bb_bandwidth', 'bb_percent', 'atr', \n",
    "            'plus_di', 'minus_di', 'adx', 'senkou_span_a', \n",
    "            'senkou_span_b', 'tenkan_sen', 'kijun_sen'\n",
    "        ]\n",
    "        \n",
    "        # Storage for different data types\n",
    "        self.raw_data: Dict[str, pd.DataFrame] = {}\n",
    "        self.normalized_data: Dict[str, pd.DataFrame] = {}\n",
    "        \n",
    "        # Thread safety\n",
    "        self.data_lock = threading.Lock()\n",
    "        self.save_queue = Queue()\n",
    "        \n",
    "        # Initialize components\n",
    "        self.indicator_manager = IndicatorManager()\n",
    "        self.data_processor = DataPreprocessor()\n",
    "        \n",
    "        # Start save worker\n",
    "        self.save_worker = threading.Thread(\n",
    "            target=self._parquet_save_worker,\n",
    "            daemon=True,\n",
    "            name=\"ParquetSaveWorker\"\n",
    "        )\n",
    "        self.save_worker.start()\n",
    "    \n",
    "    def fetch_missing_candles(self, pair: str, last_timestamp: pd.Timestamp) -> pd.DataFrame:\n",
    "        \"\"\"Fetch new candles from OANDA.\"\"\"\n",
    "        print(f\"Fetching missing candles for {pair}...\")\n",
    "        print(f'Fetch missing candles for {pair} - time {get_current_time()}')\n",
    "        params = {\n",
    "            \"from\": last_timestamp.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            \"granularity\": \"M5\",\n",
    "            \"price\": \"M\"\n",
    "        }\n",
    "        \n",
    "        r = instruments.InstrumentsCandles(instrument=pair, params=params)\n",
    "        response = client.request(r)\n",
    "        candles = response.get('candles', [])\n",
    "        \n",
    "        if not candles:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        df_list = [{\n",
    "            'timestamp': pd.to_datetime(candle['time'], utc=True),\n",
    "            'open': float(candle['mid']['o']),\n",
    "            'high': float(candle['mid']['h']),\n",
    "            'low': float(candle['mid']['l']),\n",
    "            'close': float(candle['mid']['c']),\n",
    "            # 'volume': int(candle['volume'])\n",
    "        } for candle in candles if candle['complete']]\n",
    "        \n",
    "        if not df_list:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        df = pd.DataFrame(df_list)\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "        # df.index = df.index.tz_localize('UTC')\n",
    "        print(f\"Fetched {len(df)} candles for {pair}. at time {get_current_time()}\")\n",
    "        print(df)\n",
    "        return df\n",
    "\n",
    "    def initialize_pair(self, pair: str) -> bool:\n",
    "        \"\"\"Initialize data for a pair.\"\"\"\n",
    "        try:\n",
    "            parquet_path = self.base_storage_path / f\"{pair}_5T_indics_1H_not_norm.parquet\"\n",
    "            df = pd.read_parquet(parquet_path)\n",
    "            \n",
    "            if df.index.tz is None:\n",
    "                df.index = df.index.tz_localize('UTC')\n",
    "            #! disable the logic to fetch only last 1000 datapoints for now (1000 might not be enough and check if this changes the values and confuse agent)      \n",
    "            # if len(df) > self.max_history_size:\n",
    "            #     df = df.iloc[-self.max_history_size:]\n",
    "            \n",
    "            with self.data_lock:\n",
    "                self.raw_data[pair] = df\n",
    "                self.normalized_data[pair] = self.data_processor.normalize_simple(df)\n",
    "                \n",
    "            # logger.info(f\"Initialized data for {pair}, loaded {len(df)} candles\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize {pair}: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def update_pair_data(self, pair: str) -> bool:\n",
    "        \"\"\"Update data for a pair with safer data concatenation.\"\"\"\n",
    "        print(f\"Updating data for {pair} - time {get_current_time()}\")\n",
    "\n",
    "        try:\n",
    "            with self.data_lock:\n",
    "                if pair not in self.raw_data:\n",
    "                    raise KeyError(f\"Pair {pair} not initialized\")\n",
    "                    \n",
    "                df = self.raw_data[pair]\n",
    "                print(df)\n",
    "                last_timestamp = df.index[-1]\n",
    "                print(f\"Last timestamp for {pair}: {last_timestamp}\")\n",
    "\n",
    "            current_time = pd.Timestamp.now(tz='UTC')\n",
    "            \n",
    "            if current_time - last_timestamp >= timedelta(minutes=5):\n",
    "                print(f\"Fetching new data for {pair}\")\n",
    "                return\n",
    "                new_data = self.fetch_missing_candles(pair, last_timestamp)\n",
    "                \n",
    "                if not new_data.empty:\n",
    "                    with self.data_lock:\n",
    "                        # Ensure indices are datetime and timezone-aware\n",
    "                        if df.index.tz is None:\n",
    "                            df.index = df.index.tz_localize('UTC')\n",
    "                        if new_data.index.tz is None:\n",
    "                            new_data.index = new_data.index.tz_localize('UTC')\n",
    "                        \n",
    "                        # Combine old and new data\n",
    "                        combined_df = pd.concat([df, new_data])\n",
    "                        \n",
    "                        # Remove any duplicates, keeping the latest version\n",
    "                        combined_df = combined_df[~combined_df.index.duplicated(keep='last')]\n",
    "                        \n",
    "                        # Sort by timestamp\n",
    "                        combined_df.sort_index(inplace=True)\n",
    "                        \n",
    "                        # Calculate indicators on the full dataset\n",
    "                        try:\n",
    "                            combined_df_with_indicators = self.indicator_manager.calculate_indicators(combined_df)\n",
    "                            print(f\"Successfully calculated indicators for {pair}\")\n",
    "                            \n",
    "                            # Update the stored data\n",
    "                            self.raw_data[pair] = combined_df_with_indicators\n",
    "                            \n",
    "                            # Update normalized data\n",
    "                            self.normalized_data[pair] = self.data_processor.normalize_simple(\n",
    "                                combined_df_with_indicators\n",
    "                            )\n",
    "                            \n",
    "                            # Queue the save operation\n",
    "                            try:\n",
    "                                self.save_queue.put((pair, combined_df_with_indicators))\n",
    "                                print(f\"Data queued for saving for {pair}\")\n",
    "                            except Exception as e:\n",
    "                                logger.error(f\"Error queuing save operation for {pair}: {str(e)}\")\n",
    "                                \n",
    "                            return True\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Error calculating indicators for {pair}: {str(e)}\")\n",
    "                            raise\n",
    "                            \n",
    "                else:\n",
    "                    logger.info(f\"No new data available for {pair}\")\n",
    "                    return False\n",
    "            \n",
    "            return False\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error updating data for {pair}: {str(e)}\")\n",
    "            raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SB5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
