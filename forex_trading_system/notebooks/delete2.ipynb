{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# from datetime import datetime, timedelta\n",
    "# from pathlib import Path\n",
    "# import torch as th\n",
    "# import numpy as np\n",
    "\n",
    "# # Add the project root to the Python path\n",
    "# project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "# if project_root not in sys.path:\n",
    "#     sys.path.append(project_root)\n",
    "# from stable_baselines3 import PPO, A2C, SAC, TD3\n",
    "# from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "# from trading.environments.forex_env2_flat_simple import ForexTradingEnv\n",
    "# # from trading.environments.forex_env_flat_multi_pair import MultipairForexTradingEnv\n",
    "\n",
    "# from stable_baselines3.common.callbacks import EvalCallback, BaseCallback\n",
    "# from stable_baselines3.common.monitor import Monitor\n",
    "# from data_management.dataset_manager import DatasetManager\n",
    "# from sb3_contrib import RecurrentPPO\n",
    "# from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "# from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "\n",
    "# th.set_num_threads(4)\n",
    "# N_ENVS = 4  # Number of parallel environments\n",
    "# EVAL_FREUQENCY = 200_000\n",
    "# EVAL_FREQ_ADJUSTED = int(EVAL_FREUQENCY / N_ENVS)\n",
    "\n",
    "\n",
    "# source_path = '/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/df_with_all_indics_unbiased/not_norm/train2/'\n",
    "# source_dfs = [os.path.join(source_path, f) for f in os.listdir(source_path) if f.endswith('.parquet') and not f.startswith('.') and 'validate' not in f]\n",
    "\n",
    "# eval_path = '/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/df_with_all_indics_unbiased/not_norm/train2/EUR_GBP_validate.parquet'\n",
    "# sequence = 5\n",
    "# saving_path = f'/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/df_with_all_indics_unbiased/not_norm/train/results/'\n",
    "# os.makedirs(saving_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# class ForexTensorboardCallback(BaseCallback):\n",
    "#     \"\"\"Custom callback for logging Forex trading metrics to tensorboard.\"\"\"\n",
    "    \n",
    "#     def __init__(self, verbose=0):\n",
    "#         super().__init__(verbose)\n",
    "#         self.episode_returns = []  # Track episode returns for averaging\n",
    "        \n",
    "#     def _on_step(self) -> bool:\n",
    "#         \"\"\"Called after each step in the environment.\"\"\"\n",
    "#         # infos is a list of dictionaries, one from each parallel environment\n",
    "#         for info in self.locals['infos']:\n",
    "#             if info is None:  # Skip if no info (can happen at episode boundaries)\n",
    "#                 continue\n",
    "                \n",
    "#             # Log account metrics\n",
    "#             self.logger.record(\"metrics/balance\", info['balance'])\n",
    "#             self.logger.record(\"metrics/total_return_pct\", info['total_return_pct'])\n",
    "#             self.logger.record(\"metrics/net_profit\", info['net_profit'])\n",
    "            \n",
    "#             # Log trade metrics\n",
    "#             self.logger.record(\"metrics/total_pnl\", info['total_pnl'])\n",
    "#             self.logger.record(\"metrics/total_trades\", info['total_trades'])\n",
    "#             self.logger.record(\"metrics/win_rate\", info['win_rate'])\n",
    "            \n",
    "#             # Log cost metrics\n",
    "#             self.logger.record(\"metrics/transaction_costs\", info['transaction_costs'])\n",
    "#             self.logger.record(\"metrics/transaction_costs_pct\", info['transaction_costs_pct'])\n",
    "            \n",
    "#             # Log position metrics\n",
    "#             self.logger.record(\"metrics/position_size_pct\", info['position_size_pct'])\n",
    "            \n",
    "#         return True\n",
    "    \n",
    "#     def _on_rollout_end(self) -> None:\n",
    "#         \"\"\"Called at the end of a rollout.\"\"\"\n",
    "#         # Episode metrics are handled automatically by stable-baselines3\n",
    "#         pass\n",
    "\n",
    "# class DetailedEvalCallback(EvalCallback):\n",
    "#     def _on_step(self) -> bool:\n",
    "#         \"\"\"\n",
    "#         Performs evaluation with detailed metric logging throughout the evaluation episodes.\n",
    "#         \"\"\"\n",
    "#         if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "#             # Store episode rewards for calculating mean\n",
    "#             episode_rewards = []\n",
    "#             episode_lengths = []\n",
    "            \n",
    "#             # For each evaluation episode\n",
    "#             for _ in range(self.n_eval_episodes):\n",
    "#                 episode_reward = 0\n",
    "#                 episode_length = 0\n",
    "#                 done = False\n",
    "#                 # VecEnv reset returns just the obs\n",
    "#                 obs = self.eval_env.reset()\n",
    "                \n",
    "#                 # Run episode until done\n",
    "#                 while not done:\n",
    "#                     # Get deterministic action\n",
    "#                     action, _ = self.model.predict(obs, deterministic=True)\n",
    "#                     # VecEnv step returns (obs, reward, done, info)\n",
    "#                     obs, reward, done, info = self.eval_env.step(action)\n",
    "#                     episode_reward += reward[0]  # reward is a numpy array\n",
    "#                     episode_length += 1\n",
    "                    \n",
    "#                     # Log metrics at each step\n",
    "#                     if info[0] is not None:  # info is a list of dicts\n",
    "#                         info = info[0]  # Get info dict from first env\n",
    "#                         self.logger.record(\"eval/balance\", info.get('balance', 0))\n",
    "#                         self.logger.record(\"eval/total_pnl\", info.get('total_pnl', 0))\n",
    "#                         self.logger.record(\"eval/total_trades\", info.get('total_trades', 0))\n",
    "#                         self.logger.record(\"eval/win_rate\", info.get('win_rate', 0))\n",
    "#                         self.logger.record(\"eval/transaction_costs\", info.get('transaction_costs', 0))\n",
    "#                         # Dump metrics at each step\n",
    "#                         self.logger.dump(self.n_calls)\n",
    "                \n",
    "#                 episode_rewards.append(episode_reward)\n",
    "#                 episode_lengths.append(episode_length)\n",
    "\n",
    "#             # Calculate mean metrics across episodes\n",
    "#             mean_reward = np.mean(episode_rewards)\n",
    "#             mean_length = np.mean(episode_lengths)\n",
    "            \n",
    "#             self.logger.record(\"eval/mean_reward\", mean_reward)\n",
    "#             self.logger.record(\"eval/mean_episode_length\", mean_length)\n",
    "\n",
    "#             # Update best model if needed\n",
    "#             if self.best_model_save_path is not None:\n",
    "#                 if self.verbose >= 1:\n",
    "#                     print(f\"Evaluating the current model: {mean_reward:.2f}\")\n",
    "                \n",
    "#                 if mean_reward > self.best_mean_reward:\n",
    "#                     if self.verbose >= 1:\n",
    "#                         print(f\"New best mean reward: {mean_reward:.2f} \"\n",
    "#                               f\"(previous: {self.best_mean_reward:.2f})\")\n",
    "#                     self.best_mean_reward = mean_reward\n",
    "#                     self.model.save(self.best_model_save_path)\n",
    "\n",
    "#         return True\n",
    "\n",
    "#     def _get_eval_info(self):\n",
    "#         \"\"\"Helper method to get the last info dict from eval environment.\"\"\"\n",
    "#         try:\n",
    "#             # Try to get info directly from environment\n",
    "#             if hasattr(self.eval_env, 'get_info'):\n",
    "#                 return self.eval_env.get_info()\n",
    "#             # If that's not available, try to get it from the unwrapped env\n",
    "#             elif hasattr(self.eval_env, 'envs'):\n",
    "#                 return self.eval_env.envs[0].get_info()\n",
    "#             return None\n",
    "#         except Exception as e:\n",
    "#             print(f\"Warning: Could not get eval info: {e}\")\n",
    "#             return None\n",
    "\n",
    "\n",
    "# def make_train_env(rank):\n",
    "#     def _init():\n",
    "#         env = ForexTradingEnv(\n",
    "#             df_paths=source_dfs,\n",
    "#             eval_mode=False,\n",
    "#             sequence_length=sequence,\n",
    "#         )\n",
    "#         env = Monitor(env)\n",
    "#         return env\n",
    "#     return _init\n",
    "\n",
    "\n",
    "# train_env = SubprocVecEnv([make_train_env(i) for i in range(N_ENVS)])\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True)\n",
    "\n",
    "\n",
    "\n",
    "# def make_eval_env():\n",
    "#     env = ForexTradingEnv(\n",
    "#         df_paths=source_dfs,\n",
    "#         eval_path=eval_path,\n",
    "#         eval_mode=True,\n",
    "#         pair='EUR_GBP',\n",
    "#         sequence_length=sequence,\n",
    "\n",
    "\n",
    "#     )\n",
    "#     env = Monitor(env)\n",
    "#     env = DummyVecEnv([lambda: env])\n",
    "#     env = VecNormalize(env, norm_obs=True, norm_reward=False)\n",
    "#     env.training = False\n",
    "#     return env\n",
    "\n",
    "\n",
    "# eval_env = make_eval_env()\n",
    "\n",
    "# eval_callback = DetailedEvalCallback(\n",
    "#     eval_env,\n",
    "#     best_model_save_path=f'{saving_path}eval_best_model_old_reward/',\n",
    "#     log_path=saving_path,\n",
    "#     eval_freq=EVAL_FREQ_ADJUSTED,\n",
    "#     n_eval_episodes=5,\n",
    "#     deterministic=True,\n",
    "#     render=False\n",
    "# )\n",
    "\n",
    "# # eval_callback = EvalCallback(\n",
    "# #     eval_env,\n",
    "# #     best_model_save_path=saving_path,\n",
    "# #     log_path=saving_path,\n",
    "# #     eval_freq=EVAL_FREQ_ADJUSTED,  # Adjust as needed\n",
    "# #     n_eval_episodes=5,\n",
    "# #     deterministic=True,\n",
    "# #     render=False\n",
    "# # )\n",
    "\n",
    "# model = PPO(\n",
    "#     'MlpPolicy',\n",
    "#     train_env,\n",
    "#     verbose=0,\n",
    "#     tensorboard_log=f'{saving_path}sequence_{sequence}__PPO_old_reward_12Dec/',\n",
    "# )\n",
    "# # Define policy kwargs for the LSTM configuration\n",
    "# # policy_kwargs = dict(\n",
    "# #     # Network Architecture\n",
    "# #     net_arch=dict(\n",
    "# #         # Actor (policy) network\n",
    "# #         pi=[256, 128],  # Larger first layer to process high-dimensional input\n",
    "# #         # Critic (value) network\n",
    "# #         vf=[256, 128]   # Match actor architecture for balanced learning\n",
    "# #     ),\n",
    "    \n",
    "# #     # LSTM Configuration\n",
    "# #     lstm_hidden_size=256,      # Larger hidden size to capture complex patterns\n",
    "# #     n_lstm_layers=2,           # Multiple layers for hierarchical feature learning\n",
    "# #     enable_critic_lstm=True,   # Share temporal understanding between actor and critic\n",
    "    \n",
    "# #     # LSTM specific parameters\n",
    "# #     lstm_kwargs=dict(\n",
    "# #         dropout=0.2            # Slightly higher dropout for regularization\n",
    "# #     )\n",
    "# # )\n",
    "\n",
    "# # policy_kwargs_complex = dict(\n",
    "# #     net_arch=dict(\n",
    "# #         pi=[512, 256, 128],\n",
    "# #         vf=[512, 256, 128]\n",
    "# #     ),\n",
    "# #     lstm_hidden_size=512,\n",
    "# #     n_lstm_layers=3,\n",
    "# #     enable_critic_lstm=True,\n",
    "# #     lstm_kwargs=dict(\n",
    "# #         dropout=0.25\n",
    "# #     )\n",
    "# # )\n",
    "\n",
    "# # model = RecurrentPPO(\n",
    "# #     'MlpLstmPolicy',\n",
    "# #     train_env,\n",
    "# #     verbose=0,\n",
    "# #     tensorboard_log=f'{saving_path}sequence_{sequence}_RecurrentPPO/',\n",
    "# #     policy_kwargs=policy_kwargs,\n",
    "# # )\n",
    "# callbacks = [\n",
    "#     ForexTensorboardCallback(),\n",
    "#     eval_callback\n",
    "# ]\n",
    "\n",
    "# model.learn(\n",
    "#     total_timesteps=35_000_000,  # Adjust as needed\n",
    "#     callback=callbacks\n",
    "# )\n",
    "\n",
    "# model.save(f'{saving_path}{sequence}_best_model_core.zip')\n",
    "# train_env.save(f'{saving_path}{sequence}_vec_normalize_core.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from data_management.dataset_manager import DatasetManager\n",
    "from data_management.feature_engineer import FeatureEngineer\n",
    "from data_management.preprocessor import DataPreprocessor\n",
    "\n",
    "dataset_manager = DatasetManager()\n",
    "feature_engineer =  FeatureEngineer()\n",
    "preprocessor = DataPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['open',\n",
       " 'high',\n",
       " 'low',\n",
       " 'senkou_span_a',\n",
       " 'senkou_span_b',\n",
       " 'tenkan_sen',\n",
       " 'kijun_sen',\n",
       " 'sma_20',\n",
       " 'sma_50',\n",
       " 'macd',\n",
       " 'macd_signal',\n",
       " 'macd_hist']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_norm_needed= ['bb_position', 'dist_sma_20_atr_adj', 'dist_sma_50_atr_adj', 'sma_cross_atr', 'tenkan_dist_atr_adj', 'kijun_dist_atr_adj']\n",
    "#remove\n",
    "ohlc_cols = ['open', 'high', 'low']\n",
    "ichi = ['senkou_span_a', 'senkou_span_b', 'tenkan_sen', 'kijun_sen']\n",
    "sma = ['sma_20', 'sma_50']\n",
    "macd = ['macd', 'macd_signal', 'macd_hist']\n",
    "cols_to_drop_from_obs = ohlc_cols + ichi + sma + macd\n",
    "cols_to_drop_from_obs\n",
    "\n",
    "#! Make next iteration only with core featurs\n",
    "core_features = [\n",
    "    'price_change',          # Primary momentum\n",
    "    'close_norm',           # Normalized price level\n",
    "    'rsi',                  # Core momentum\n",
    "    'rsi_change',          # Momentum shift\n",
    "    'stoch_d',             # Slower momentum confirmation\n",
    "    'bb_position',         # Volatility context\n",
    "    'bb_width_normalized', # Volatility expansion/contraction\n",
    "    'dist_sma_20_atr_adj', # Short-term trend deviation\n",
    "    'dist_sma_50_atr_adj', # Medium-term trend deviation\n",
    "    'sma_cross_atr',       # Trend change signal\n",
    "    'macd_hist_norm',      # Momentum divergence\n",
    "    'di_spread',           # Trend strength\n",
    "    'trend_strength',      # Combined directional movement\n",
    "    'atr_regime_20',       # Volatility regime\n",
    "    'trend_strength_20',   # Price momentum vs volatility\n",
    "    'trend_strength_50',   # Longer-term momentum vs volatility\n",
    "    'momentum_1h',         # Short-term momentum\n",
    "    'momentum_4h',          # Medium-term momentum\n",
    "    'close'\n",
    "]\n",
    "\n",
    "core_features2 = [\n",
    "    'price_change',          # Primary momentum\n",
    "    'close_norm',           # Normalized price level\n",
    "    'rsi',                  # Core momentum\n",
    "\n",
    "    'stoch_d',             # Slower momentum confirmation\n",
    "    'bb_position',         # Volatility context\n",
    "    'bb_width_normalized', # Volatility expansion/contraction\n",
    "    'dist_sma_20_atr_adj', # Short-term trend deviation\n",
    "    'dist_sma_50_atr_adj', # Medium-term trend deviation\n",
    "\n",
    "    'macd_hist_norm',      # Momentum divergence\n",
    "    'di_spread',           # Trend strength\n",
    "    'trend_strength',      # Combined directional movement\n",
    "    'atr_regime_20',       # Volatility regime\n",
    "\n",
    "    'momentum_1h',         # Short-term momentum\n",
    "    'momentum_4h',          # Medium-term momentum\n",
    "    'close'\n",
    "]\n",
    "core_features3 = [\n",
    "    'price_change',          # Primary momentum\n",
    "    'close_norm',           # Normalized price level\n",
    "    'rsi',                  # Core momentum\n",
    "\n",
    "    # 'stoch_d',             # Slower momentum confirmation\n",
    "    # 'bb_position',         # Volatility context\n",
    "    # 'bb_width_normalized', # Volatility expansion/contraction\n",
    "    # 'dist_sma_20_atr_adj', # Short-term trend deviation\n",
    "    # 'dist_sma_50_atr_adj', # Medium-term trend deviation\n",
    "\n",
    "    'macd_hist_norm',      # Momentum divergence\n",
    "    # 'di_spread',           # Trend strength\n",
    "    # 'trend_strength',      # Combined directional movement\n",
    "    # 'atr_regime_20',       # Volatility regime\n",
    "\n",
    "    # 'momentum_1h',         # Short-term momentum\n",
    "    # 'momentum_4h',          # Medium-term momentum\n",
    "    'close'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split sizes:\n",
      "Training: 101899 samples (70.0%)\n",
      "Validation: 21836 samples (15.0%)\n",
      "Test: 21836 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101872 samples (70.0%)\n",
      "Validation: 21830 samples (15.0%)\n",
      "Test: 21830 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 102874 samples (70.0%)\n",
      "Validation: 22045 samples (15.0%)\n",
      "Test: 22045 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101881 samples (70.0%)\n",
      "Validation: 21832 samples (15.0%)\n",
      "Test: 21832 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101876 samples (70.0%)\n",
      "Validation: 21831 samples (15.0%)\n",
      "Test: 21831 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101867 samples (70.0%)\n",
      "Validation: 21829 samples (15.0%)\n",
      "Test: 21829 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 93392 samples (70.0%)\n",
      "Validation: 20013 samples (15.0%)\n",
      "Test: 20013 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101878 samples (70.0%)\n",
      "Validation: 21831 samples (15.0%)\n",
      "Test: 21831 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101882 samples (70.0%)\n",
      "Validation: 21832 samples (15.0%)\n",
      "Test: 21832 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101888 samples (70.0%)\n",
      "Validation: 21833 samples (15.0%)\n",
      "Test: 21834 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101879 samples (70.0%)\n",
      "Validation: 21831 samples (15.0%)\n",
      "Test: 21832 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101878 samples (70.0%)\n",
      "Validation: 21831 samples (15.0%)\n",
      "Test: 21831 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101866 samples (70.0%)\n",
      "Validation: 21829 samples (15.0%)\n",
      "Test: 21829 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 93376 samples (70.0%)\n",
      "Validation: 20009 samples (15.0%)\n",
      "Test: 20010 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101375 samples (70.0%)\n",
      "Validation: 21723 samples (15.0%)\n",
      "Test: 21724 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n",
      "Dataset split sizes:\n",
      "Training: 101000 samples (70.0%)\n",
      "Validation: 21643 samples (15.0%)\n",
      "Test: 21643 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "# gold = pd.read_parquet('/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/df_with_all_indics_unbiased/not_norm/XAU_USD_5min_1D_not_norm_10dec.parquet')\n",
    "\n",
    "hourly_source_dir = \"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/unbiased/not_norm/\"\n",
    "source_path = '/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/df_with_all_indics_unbiased/not_norm/'\n",
    "source_dfs = [os.path.join(hourly_source_dir, f) for f in os.listdir(hourly_source_dir) if f.endswith('.parquet') and not f.startswith('.')]\n",
    "output_path = '/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/unbiased/not_norm/train3_minimal_indic/'\n",
    "\n",
    "\n",
    "# Create an empty list to store our dataframes\n",
    "all_dfs = []\n",
    "for filepath in source_dfs:\n",
    "    name = Path(filepath).name\n",
    "    ticker = '_'.join(name.split('_')[:2])\n",
    "    df = pd.read_parquet(filepath)\n",
    "    train_df, val_df, test_df = dataset_manager.split_dataset(df)\n",
    "    df_indic = feature_engineer.enhance_features(train_df)\n",
    "    df_norm = preprocessor.normalize_simple(df_indic)\n",
    "    # df_norm = df_norm.drop(columns=cols_to_drop_from_obs)\n",
    "    df_norm = df_norm[core_features3]\n",
    "    df_norm.to_parquet(os.path.join(output_path, f'{ticker}_train_1h_1d.parquet'))\n",
    "    # Create a single-row dataframe with just the ticker\n",
    "    # ticker_df = pd.DataFrame({'ticker': [ticker]})\n",
    "    \n",
    "    # Get last 30 rows of normalized data\n",
    "    # last_30_rows = df_norm.head(10)\n",
    "    \n",
    "    # # Add both dataframes to our list\n",
    "    # all_dfs.append(ticker_df)\n",
    "    # all_dfs.append(last_30_rows)\n",
    "# Concatenate all dataframes\n",
    "# final_df = pd.concat(all_dfs, axis=0)\n",
    "\n",
    "# Save to CSV\n",
    "# final_df.to_csv(os.path.join(output_path, 'comparison_samples1.csv'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split sizes:\n",
      "Training: 101878 samples (70.0%)\n",
      "Validation: 21831 samples (15.0%)\n",
      "Test: 21831 samples (15.0%)\n",
      "Warning: No normalization rule for price_change\n",
      "Warning: No normalization rule for close_norm\n",
      "Warning: No normalization rule for hl_range_ratio\n",
      "Warning: No normalization rule for atr_normalized\n",
      "Warning: No normalization rule for dist_sma_20_atr_adj\n",
      "Warning: No normalization rule for dist_sma_50_atr_adj\n",
      "Warning: No normalization rule for sma_cross_atr\n",
      "Warning: No normalization rule for bb_position\n",
      "Warning: No normalization rule for bb_width_normalized\n",
      "Warning: No normalization rule for tenkan_dist_atr_adj\n",
      "Warning: No normalization rule for kijun_dist_atr_adj\n",
      "Warning: No normalization rule for rsi_change\n",
      "Warning: No normalization rule for macd_hist_norm\n",
      "Warning: No normalization rule for atr_regime_10\n",
      "Warning: No normalization rule for atr_regime_20\n",
      "Warning: No normalization rule for trend_strength_20\n",
      "Warning: No normalization rule for trend_strength_50\n",
      "Warning: No normalization rule for momentum_1h\n",
      "Warning: No normalization rule for momentum_4h\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/unbiased/not_norm/EUR_GBP_1h_1D_not_norm_unbiased.parquet')\n",
    "output_path = '/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/unbiased/not_norm/train3_minimal_indic/'\n",
    "\n",
    "name = Path('/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/unbiased/not_norm/EUR_GBP_1h_1D_not_norm_unbiased.parquet').name\n",
    "ticker = '_'.join(name.split('_')[:2])\n",
    "\n",
    "train_df, val_df, test_df = dataset_manager.split_dataset(df)\n",
    "df_indic = feature_engineer.enhance_features(val_df)\n",
    "df_norm = preprocessor.normalize_simple(df_indic)\n",
    "df_norm = df_norm[core_features3]\n",
    "df_norm.to_parquet(os.path.join(output_path, f'{ticker}_validate.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SB5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
