{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "from typing import List, Optional\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "from data_management.indicator_manager import IndicatorManager\n",
    "\n",
    "from data_management.preprocessor import DataPreprocessor\n",
    "\n",
    "processor = DataPreprocessor()\n",
    "\n",
    "\n",
    "indicator_manager = IndicatorManager()\n",
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('dataset_prep.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('dataset_prep')\n",
    "\n",
    "\n",
    "def prepare_unbiased_dataset_row_by_row(\n",
    "    df_5min: pd.DataFrame, \n",
    "    indicator_manager,\n",
    "    indicator_timeframe: str = '1h',\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare dataset with technical indicators calculated without look-ahead bias,\n",
    "    processing data row by row.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with 1-minute OHLC data and UTC timezone index\n",
    "        indicator_manager: IndicatorManager instance\n",
    "        indicator_timeframe: Timeframe to aggregate data for indicator calculation (e.g., '1h', '4h', '1d')\n",
    "        verbose: Whether to print progress information\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with 5-minute candles and indicators calculated at specified timeframe\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        logger.info(\"Starting data preparation using row-by-row method...\")\n",
    "\n",
    "    # Ensure UTC timezone\n",
    "    if df_5min.index.tz is None:\n",
    "        df_5min.index = df_5min.index.tz_localize('UTC')\n",
    "    elif df_5min.index.tz != pytz.UTC:\n",
    "        df_5min.index = df_5min.index.tz_convert('UTC')\n",
    "\n",
    "    # Create 5-minute OHLC data\n",
    "    # df_5min = df.resample('5min').agg({\n",
    "    #     'open': 'first',\n",
    "    #     'high': 'max',\n",
    "    #     'low': 'min',\n",
    "    #     'close': 'last'\n",
    "    # }).dropna()\n",
    "    # df_5min = df\n",
    "\n",
    "    if verbose:\n",
    "        logger.info(f\"Resampled to 5-minute candles. Shape: {df_5min.shape}\")\n",
    "\n",
    "    # Convert indicator_timeframe to minutes\n",
    "    timeframe_minutes = int(pd.Timedelta(indicator_timeframe).total_seconds() / 60)\n",
    "\n",
    "    # Get maximum periods required by indicators\n",
    "    max_indicator_periods = 60\n",
    "\n",
    "    if verbose:\n",
    "        logger.info(f\"Maximum indicator periods required: {max_indicator_periods}\")\n",
    "\n",
    "    # Initialize list to collect results\n",
    "    results = []\n",
    "\n",
    "    # Progress bar setup\n",
    "    if verbose:\n",
    "        iterator = tqdm(df_5min.iterrows(), total=len(df_5min), desc='Processing rows')\n",
    "    else:\n",
    "        iterator = df_5min.iterrows()\n",
    "\n",
    "    # Initialize a DataFrame to cache data for the rolling window\n",
    "    data_cache = pd.DataFrame(columns=['open', 'high', 'low', 'close'])\n",
    "\n",
    "    for idx, row in iterator:\n",
    "        # Append the current row to the cache\n",
    "        data_cache.loc[idx] = row\n",
    "\n",
    "        # Remove data older than necessary for the indicator calculations\n",
    "        earliest_time = idx - pd.Timedelta(minutes=(timeframe_minutes * max_indicator_periods))\n",
    "   \n",
    "        data_cache = data_cache.loc[data_cache.index >= earliest_time]\n",
    "\n",
    "        # Get data up to the current time for indicator calculation\n",
    "        data_up_to_now = data_cache.loc[:idx]\n",
    "\n",
    "        # Aggregate data to the indicator timeframe up to the current time\n",
    "        period_data = data_up_to_now.resample(indicator_timeframe, closed='right', label='right').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last'\n",
    "        }).dropna()\n",
    "\n",
    "        # Check if we have enough periods in period_data for indicators\n",
    "        if len(period_data) < max_indicator_periods:\n",
    "            # Not enough data yet to calculate indicators\n",
    "            continue\n",
    "\n",
    "        # Calculate indicators on period_data\n",
    "        indicators_df = indicator_manager.calculate_indicators(\n",
    "            period_data,\n",
    "            indicator_timeframe=None  # Data is already aggregated\n",
    "        )\n",
    "\n",
    "        if indicators_df.empty:\n",
    "            # Not enough data, skip\n",
    "            continue\n",
    "\n",
    "        # Get the last row of indicators\n",
    "        try:\n",
    "            indicators = indicators_df.iloc[-1]\n",
    "        except IndexError:\n",
    "            # indicators_df is empty\n",
    "            continue\n",
    "\n",
    "        # Combine the current 5-minute data with indicators\n",
    "        combined_row = pd.concat([row, indicators])\n",
    "\n",
    "        # Append combined_row to results\n",
    "        results.append(combined_row)\n",
    "\n",
    "    # Create final DataFrame\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    # Drop any rows with NaN values in the indicators (e.g., initial periods)\n",
    "    result_df.dropna(inplace=True)\n",
    "\n",
    "    if verbose and not result_df.empty:\n",
    "        logger.info(f\"\\nFinal dataset prepared. Shape: {result_df.shape}\")\n",
    "        logger.info(f\"Date range: {result_df.index[0]} to {result_df.index[-1]}\")\n",
    "    elif verbose:\n",
    "        logger.info(\"\\nNo data was processed. Please check if there is sufficient data for indicator calculation.\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def process_currency_pairs(\n",
    "    currencies: List[str],\n",
    "    base_path: str = './',\n",
    "    indicator_timeframe: str = '1h'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process multiple currency pairs with unbiased indicator calculation using row-by-row method.\n",
    "\n",
    "    Args:\n",
    "        currencies: List of currency pairs to process\n",
    "        base_path: Base path for data storage\n",
    "        indicator_timeframe: Timeframe for indicator calculation\n",
    "\n",
    "    Returns:\n",
    "        Processed DataFrame for inspection\n",
    "    \"\"\"\n",
    "    for ccy in currencies:\n",
    "        logger.info(f\"\\nProcessing {ccy}...\")\n",
    "        source_5min = f'../deployment/raw_data/{ccy}_raw_5min.parquet'\n",
    "\n",
    "        try:\n",
    "            # Read source data\n",
    "            df = pd.read_parquet(source_5min)\n",
    "\n",
    "            # Prepare dataset with unbiased indicators\n",
    "            df_with_indicators = prepare_unbiased_dataset_row_by_row(\n",
    "                df_5min=df,\n",
    "                indicator_manager=indicator_manager,\n",
    "                indicator_timeframe=indicator_timeframe,\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "            if df_with_indicators.empty:\n",
    "                logger.info(f\"No data processed for {ccy}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            output_path_not_norm = f'{base_path}/{ccy}_5min_indics_{indicator_timeframe}_not_norm_unbiased.parquet'\n",
    "            df_with_indicators.to_parquet(output_path_not_norm)\n",
    "            # Normalize the data\n",
    "            logger.info(\"\\nNormalizing data...\")\n",
    "            df_norm = processor.normalize_simple(df=df_with_indicators)\n",
    "\n",
    "            # Save results\n",
    "            output_path = f'{base_path}/{ccy}_5min_indics_{indicator_timeframe}_norm_unbiased.parquet'\n",
    "          \n",
    "            df_norm.to_parquet(output_path)\n",
    "\n",
    "            logger.info(f\"Completed processing {ccy}\")\n",
    "            return df_norm  # Return for inspection\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.info(f\"Error processing {ccy}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "currencies_1 = [\n",
    "            'GBP_CHF', 'GBP_JPY', 'EUR_CHF', \n",
    " \n",
    "        ]\n",
    "currencies_2 = [\n",
    "\n",
    "            'EUR_CAD', 'EUR_USD', 'GBP_USD', \n",
    "    \n",
    "        ]\n",
    "currencies_3 = [\n",
    "\n",
    "            'USD_CAD', 'AUD_USD', 'CHF_JPY', \n",
    " \n",
    "        ]\n",
    "currencies_4 = [\n",
    "\n",
    "            'NZD_JPY', 'XAU_USD', 'XAG_USD', \n",
    "        ]\n",
    "currencies_5 = [\n",
    "\n",
    "            'USD_CHF', 'USD_JPY', 'AUD_JPY', \n",
    "        ]\n",
    "currencies_6 = [\n",
    "\n",
    "            'EUR_JPY', 'EUR_GBP', 'NZD_USD',\n",
    "        ]\n",
    "\n",
    "\n",
    "df = process_currency_pairs(\n",
    "    currencies=currencies_2,\n",
    "    indicator_timeframe='1h'\n",
    ")\n",
    "\n",
    "# df  # For inspection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_max_indicator_periods(indicator_params):\n",
    "#     \"\"\"Calculate the maximum number of periods required by all indicators.\"\"\"\n",
    "#     max_period = 0\n",
    "#     for indicator, params in indicator_params.items():\n",
    "#         if indicator == 'sma':\n",
    "#             max_period = max(max_period, max(params.get('periods', [0])))\n",
    "#         elif indicator == 'rsi':\n",
    "#             max_period = max(max_period, params.get('period', 0))\n",
    "#         elif indicator == 'macd':\n",
    "#             max_period = max(max_period, params.get('slowperiod', 0))\n",
    "#         elif indicator == 'bollinger':\n",
    "#             max_period = max(max_period, params.get('timeperiod', 0))\n",
    "#         elif indicator == 'atr':\n",
    "#             max_period = max(max_period, params.get('period', 0))\n",
    "#         elif indicator == 'adx':\n",
    "#             max_period = max(max_period, params.get('period', 0))\n",
    "#         elif indicator == 'dmi':\n",
    "#             max_period = max(max_period, params.get('period', 0))\n",
    "#         elif indicator == 'ichimoku':\n",
    "#             # Ichimoku uses standard periods of 9, 26, and 52\n",
    "#             max_period = max(max_period, 52)\n",
    "#     return max_period\n",
    "\n",
    "# max_indicator_periods = get_max_indicator_periods(indicator_manager.indicator_params)\n",
    "\n",
    "# max_indicator_periods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SB5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
