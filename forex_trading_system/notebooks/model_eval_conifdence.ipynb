{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Tuple\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.policies import obs_as_tensor\n",
    "from trading.environments.forex_env2_flat import ForexTradingEnv\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                   format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str,\n",
    "        vec_normalize_path: str,\n",
    "        test_df: pd.DataFrame,\n",
    "        pair: str,\n",
    "        save_path: Optional[str] = None,\n",
    "        sequence_length: int = 5\n",
    "    ):\n",
    "        self.pair = pair\n",
    "        self.sequence_length = sequence_length\n",
    "        self.test_df = test_df\n",
    "        self.save_path = Path(save_path) if save_path else Path(\"evaluation_results\")\n",
    "        self.save_path.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        # Load model and normalization\n",
    "        self.model = PPO.load(model_path)\n",
    "        self.vec_normalize = VecNormalize.load(vec_normalize_path, None)\n",
    "        \n",
    "        # Create evaluation environment\n",
    "        self.env = self._create_test_env()\n",
    "        \n",
    "    def _create_test_env(self) -> VecNormalize:\n",
    "        \"\"\"Creates a properly normalized test environment.\"\"\"\n",
    "        def make_env():\n",
    "            env = ForexTradingEnv(\n",
    "                df=self.test_df,\n",
    "                pair=self.pair,\n",
    "                sequence_length=self.sequence_length,\n",
    "                random_start=False\n",
    "            )\n",
    "            return Monitor(env)\n",
    "        \n",
    "        vec_env = DummyVecEnv([make_env])\n",
    "        \n",
    "        test_env = VecNormalize(\n",
    "            vec_env,\n",
    "            training=False,\n",
    "            norm_obs=self.vec_normalize.norm_obs,\n",
    "            norm_reward=False,\n",
    "  \n",
    "            epsilon=self.vec_normalize.epsilon\n",
    "        )\n",
    "        \n",
    "        # Copy normalization statistics\n",
    "        test_env.obs_rms = self.vec_normalize.obs_rms\n",
    "        test_env.ret_rms = self.vec_normalize.ret_rms\n",
    "        \n",
    "        return test_env\n",
    "    \n",
    "    def get_action_probabilities(self, observation: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Gets action probabilities using the proper SB3 method.\"\"\"\n",
    "        # Convert observation to tensor on correct device\n",
    "        obs_tensor = obs_as_tensor(observation, self.model.policy.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get distribution from policy\n",
    "            dist = self.model.policy.get_distribution(obs_tensor)\n",
    "            # Get raw probabilities\n",
    "            probs = dist.distribution.probs\n",
    "            probs_np = probs.cpu().numpy()[0]\n",
    "            \n",
    "            # Convert to dictionary\n",
    "            action_map = {0: 'NO_POSITION', 1: 'LONG', 2: 'SHORT'}\n",
    "            prob_dict = {action_map[i]: float(p) for i, p in enumerate(probs_np)}\n",
    "            \n",
    "            # Calculate entropy for uncertainty measure\n",
    "            entropy = -np.sum(probs_np * np.log(probs_np + 1e-10))\n",
    "            prob_dict['entropy'] = float(entropy)\n",
    "            \n",
    "            return prob_dict\n",
    "    \n",
    "    def evaluate(self, n_episodes: int = 1) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Runs evaluation and returns both step and trade data.\"\"\"\n",
    "        all_steps_data = []\n",
    "        all_trades_data = []\n",
    "        \n",
    "        for episode in range(n_episodes):\n",
    "            steps_data, trades_data = self._run_episode()\n",
    "            all_steps_data.extend(steps_data)\n",
    "            all_trades_data.extend(trades_data)\n",
    "            \n",
    "            # Convert to DataFrames\n",
    "            steps_df = pd.DataFrame(all_steps_data)\n",
    "            trades_df = pd.DataFrame(all_trades_data) if all_trades_data else pd.DataFrame()\n",
    "            \n",
    "            # Print episode summary\n",
    "            self._print_episode_summary(steps_df, trades_df)\n",
    "            \n",
    "            # Save results\n",
    "            steps_df.to_csv(self.save_path / f\"{self.pair}_steps_analysis.csv\", index=False)\n",
    "            if not trades_df.empty:\n",
    "                trades_df.to_csv(self.save_path / f\"{self.pair}_trades_analysis.csv\", index=False)\n",
    "            \n",
    "        return steps_df, trades_df\n",
    "    \n",
    "    def _run_episode(self) -> Tuple[list, list]:\n",
    "        \"\"\"Executes single evaluation episode.\"\"\"\n",
    "        obs = self.env.reset()\n",
    "        done = False\n",
    "        steps_data = []\n",
    "        trades_data = []\n",
    "        \n",
    "        while not done:\n",
    "            # Get action probabilities\n",
    "            action_probs = self.get_action_probabilities(obs)\n",
    "            \n",
    "            # Get deterministic action (highest probability)\n",
    "            action = max(\n",
    "                {k: v for k, v in action_probs.items() if k != 'entropy'}.items(),\n",
    "                key=lambda x: x[1]\n",
    "            )[0]\n",
    "            action_idx = {'NO_POSITION': 0, 'LONG': 1, 'SHORT': 2}[action]\n",
    "            \n",
    "            # Take action\n",
    "            next_obs, reward, done, info = self.env.step([action_idx])\n",
    "            # Extract from vectorized env\n",
    "            reward, done, info = reward[0], done[0], info[0]\n",
    "            \n",
    "            # Record step data\n",
    "            step_info = {\n",
    "                'timestamp': info['timestamp'],\n",
    "                'action': action,\n",
    "                'highest_prob': max(v for k, v in action_probs.items() if k != 'entropy'),\n",
    "                'no_position_prob': action_probs['NO_POSITION'],\n",
    "                'long_prob': action_probs['LONG'],\n",
    "                'short_prob': action_probs['SHORT'],\n",
    "                'entropy': action_probs['entropy'],\n",
    "                'position_type': info['position_type'],\n",
    "                'balance': info['balance'],\n",
    "                'unrealized_pnl': info['unrealized_pnl'],\n",
    "                'net_worth_chg': info['net_worth_chg'],\n",
    "                'reward': reward\n",
    "            }\n",
    "            steps_data.append(step_info)\n",
    "            \n",
    "            # Record trade data if trade was closed\n",
    "            if info.get('trade_closed', False):\n",
    "                trade_info = {\n",
    "                    'entry_time': info['entry_time'],\n",
    "                    'exit_time': info['exit_time'],\n",
    "                    'trade_duration': (info['exit_time'] - info['entry_time']).total_seconds() / 3600,\n",
    "                    'position_type': info['position_type'],\n",
    "                    'entry_price': info['entry_price'],\n",
    "                    'exit_price': info['exit_price'],\n",
    "                    'entry_prob': action_probs[info['position_type']],\n",
    "                    'exit_prob': action_probs['NO_POSITION'],\n",
    "                    'pnl': info['trade_pnl'],\n",
    "                    'entry_entropy': action_probs['entropy']\n",
    "                }\n",
    "                trades_data.append(trade_info)\n",
    "            \n",
    "            obs = next_obs\n",
    "            \n",
    "        return steps_data, trades_data\n",
    "    \n",
    "    def _print_episode_summary(self, steps_df: pd.DataFrame, trades_df: pd.DataFrame):\n",
    "        \"\"\"Prints comprehensive episode summary with conviction analysis.\"\"\"\n",
    "        logger.info(\"\\nEpisode Summary:\")\n",
    "        logger.info(\"-\" * 50)\n",
    "        \n",
    "        # Performance metrics\n",
    "        total_return = ((steps_df['balance'].iloc[-1] / steps_df['balance'].iloc[0]) - 1) * 100\n",
    "        \n",
    "        # Base metrics\n",
    "        logger.info(f\"Total Return: {total_return:.2f}%\")\n",
    "        logger.info(f\"Initial Balance: ${steps_df['balance'].iloc[0]:,.2f}\")\n",
    "        logger.info(f\"Final Balance: ${steps_df['balance'].iloc[-1]:,.2f}\")\n",
    "        \n",
    "        if not trades_df.empty:\n",
    "            # Trade metrics\n",
    "            total_trades = len(trades_df)\n",
    "            winning_trades = (trades_df['pnl'] > 0).sum()\n",
    "            win_rate = (winning_trades / total_trades) * 100\n",
    "            \n",
    "            logger.info(f\"\\nTrade Analysis:\")\n",
    "            logger.info(f\"Total Trades: {total_trades}\")\n",
    "            logger.info(f\"Win Rate: {win_rate:.1f}%\")\n",
    "            logger.info(f\"Average Trade PnL: ${trades_df['pnl'].mean():.2f}\")\n",
    "            logger.info(f\"Average Trade Duration: {trades_df['trade_duration'].mean():.1f} hours\")\n",
    "            \n",
    "            # Conviction analysis\n",
    "            logger.info(f\"\\nConviction Analysis:\")\n",
    "            logger.info(f\"Average Entry Conviction: {trades_df['entry_prob'].mean():.3f}\")\n",
    "            logger.info(f\"Winning Trades Conviction: {trades_df[trades_df['pnl'] > 0]['entry_prob'].mean():.3f}\")\n",
    "            logger.info(f\"Losing Trades Conviction: {trades_df[trades_df['pnl'] <= 0]['entry_prob'].mean():.3f}\")\n",
    "            \n",
    "        logger.info(\"-\" * 50)\n",
    "\n",
    "def evaluate_model(\n",
    "    model_path: str,\n",
    "    vec_normalize_path: str,\n",
    "    test_df: pd.DataFrame,\n",
    "    pair: str,\n",
    "    save_path: Optional[str] = None\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Convenience function for model evaluation.\"\"\"\n",
    "    evaluator = ModelEvaluator(\n",
    "        model_path=model_path,\n",
    "        vec_normalize_path=vec_normalize_path,\n",
    "        test_df=test_df,\n",
    "        pair=pair,\n",
    "        save_path=save_path\n",
    "    )\n",
    "    \n",
    "    return evaluator.evaluate(n_episodes=1)\n",
    "\n",
    "\n",
    "steps_df, trades_df = evaluate_model(\n",
    "    model_path=\"models/EUR_USD_model.zip\",\n",
    "    vec_normalize_path=\"models/EUR_USD_vec_normalize.pkl\",\n",
    "    test_df=test_df,\n",
    "    pair=\"EUR_USD\",\n",
    "    save_path=\"evaluation_results\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'sma_20', 'sma_50', 'rsi', 'macd',\n",
       "       'macd_signal', 'macd_hist', 'bb_upper', 'bb_middle', 'bb_lower',\n",
       "       'bb_bandwidth', 'bb_percent', 'atr', 'plus_di', 'minus_di', 'adx',\n",
       "       'senkou_span_a', 'senkou_span_b', 'tenkan_sen', 'kijun_sen'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/best_dataframes/CHF_JPY_5T_indics_1H_norm.parquet')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_management.dataset_manager import DatasetManager\n",
    "\n",
    "TICKER = 'AUD_JPY'\n",
    "dataframe_dir = f'/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/best_dataframes/{TICKER}_5T_indics_1H_norm.parquet'\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_parquet(dataframe_dir)\n",
    "dataset_manager = DatasetManager()\n",
    "train_df, val_df, test_df = dataset_manager.split_dataset(df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "\n",
    "# Load your trained model and normalization wrapper\n",
    "def make_env():\n",
    "    return ForexTradingEnv(\n",
    "        df=test_df,  # Your test DataFrame\n",
    "        pair=TICKER,\n",
    "        initial_balance=1_000_000.0,\n",
    "        # trade_size=100_000.0,\n",
    "        random_start=False\n",
    "    )\n",
    "\n",
    "# Create vectorized environment\n",
    "env = DummyVecEnv([make_env])\n",
    "env = VecNormalize(\n",
    "    env,\n",
    "    norm_obs=True,\n",
    "    norm_reward=False,  # Disable reward normalization for evaluation\n",
    "\n",
    ")\n",
    "# Print current environment's observation space shape\n",
    "print(\"New environment observation space shape:\", env.observation_space.shape)\n",
    "\n",
    "model_and_env_path = '/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/best_dataframes_true_cost/models_and_vecs'\n",
    "\n",
    "\n",
    "model = PPO.load(f\"{model_and_env_path}/{TICKER}_best_model.zip\")\n",
    "vec_normalize = VecNormalize.load(f\"{model_and_env_path}/{TICKER}_vec_normalize.pkl\", env)\n",
    "print(\"Saved environment observation space shape:\", vec_normalize.observation_space.shape)\n",
    "\n",
    "\n",
    "env = DummyVecEnv([make_env])\n",
    "\n",
    "\n",
    "# Run evaluation\n",
    "results_df = evaluate_trained_model(\n",
    "    model=model,\n",
    "    vec_normalize=vec_normalize,  # Pass the saved normalization wrapper\n",
    "    test_df=test_df,\n",
    "    pair=TICKER,\n",
    "    save_path=\"model_evaluation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.policies import obs_as_tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, Optional\n",
    "\n",
    "class PolicyAnalyzer:\n",
    "    \"\"\"Analyzes policy decisions and confidence using proper SB3 methods.\"\"\"\n",
    "    \n",
    "    def get_action_probabilities(self, pair: str, observation: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Get probability distribution over actions using SB3's native methods.\n",
    "        \n",
    "        Args:\n",
    "            pair: Currency pair\n",
    "            observation: Current observation vector\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping action names to their probabilities\n",
    "        \"\"\"\n",
    "        if pair not in self.models:\n",
    "            raise KeyError(f\"No model loaded for {pair}\")\n",
    "            \n",
    "        model = self.models[pair]\n",
    "        \n",
    "        # Convert observation to tensor on correct device\n",
    "        obs_tensor = obs_as_tensor(observation.reshape(1, -1), model.policy.device)\n",
    "        \n",
    "        # Get distribution from policy\n",
    "        with torch.no_grad():\n",
    "            dist = model.policy.get_distribution(obs_tensor)\n",
    "            # Get probabilities from distribution\n",
    "            probs = dist.distribution.probs\n",
    "            probs_np = probs.cpu().numpy()[0]  # Move to CPU and convert to numpy\n",
    "            \n",
    "        # Map probabilities to actions\n",
    "        action_map = {0: 'NO_POSITION', 1: 'LONG', 2: 'SHORT'}\n",
    "        return {action_map[i]: float(prob) for i, prob in enumerate(probs_np)}\n",
    "    \n",
    "    def predict_with_confidence(\n",
    "        self, \n",
    "        pair: str, \n",
    "        observation: np.ndarray,\n",
    "        conviction_threshold: float = 0.6\n",
    "    ) -> Tuple[str, float, Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Make a prediction and return action with confidence metrics.\n",
    "        \n",
    "        Args:\n",
    "            pair: Currency pair\n",
    "            observation: Current observation\n",
    "            conviction_threshold: Minimum probability required for action\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (chosen action, confidence score, all probabilities)\n",
    "        \"\"\"\n",
    "        # Get probability distribution\n",
    "        action_probs = self.get_action_probabilities(pair, observation)\n",
    "        \n",
    "        # Find action with highest probability\n",
    "        max_action = max(action_probs.items(), key=lambda x: x[1])\n",
    "        chosen_action, confidence = max_action\n",
    "        \n",
    "        # Calculate entropy as uncertainty measure\n",
    "        probs = np.array(list(action_probs.values()))\n",
    "        entropy = -np.sum(probs * np.log(probs + 1e-10))\n",
    "        \n",
    "        return chosen_action, confidence, {\n",
    "            'probabilities': action_probs,\n",
    "            'entropy': entropy,\n",
    "            'exceeds_threshold': confidence >= conviction_threshold\n",
    "        }\n",
    "\n",
    "def trading_cycle(self):\n",
    "    \"\"\"Execute trading cycle with improved probability analysis.\"\"\"\n",
    "    logger.info(\"Starting trading cycle\")\n",
    "    current_time = datetime.now(timezone.utc)\n",
    "    \n",
    "    for pair in currency_pairs:\n",
    "        try:\n",
    "            if pair not in self.models:\n",
    "                continue\n",
    "                \n",
    "            # Update market data\n",
    "            if self.data_manager.update_pair_data(pair):\n",
    "                with self.positions_lock:\n",
    "                    current_position_type = self.positions.get(pair, 'NO_POSITION')\n",
    "                    \n",
    "                # Get prediction data\n",
    "                observation, last_timestamp = self.data_manager.get_prediction_data(\n",
    "                    pair=pair,\n",
    "                    sequence_length=5,\n",
    "                    current_position=self.position_to_float(current_position_type)\n",
    "                )\n",
    "                \n",
    "                # Get prediction with confidence analysis\n",
    "                action, confidence, metrics = self.predict_with_confidence(\n",
    "                    pair, \n",
    "                    observation,\n",
    "                    conviction_threshold=0.6\n",
    "                )\n",
    "                \n",
    "                # Log detailed prediction metrics\n",
    "                logger.info(f\"{pair} prediction analysis:\")\n",
    "                logger.info(f\"Action probabilities: {metrics['probabilities']}\")\n",
    "                logger.info(f\"Chosen action: {action} with confidence: {confidence:.3f}\")\n",
    "                logger.info(f\"Decision entropy: {metrics['entropy']:.3f}\")\n",
    "                \n",
    "                # Execute trade only if confidence exceeds threshold\n",
    "                if metrics['exceeds_threshold'] and action != current_position_type:\n",
    "                    if self.execute_trade(pair, current_position_type, action):\n",
    "                        # Record trade with confidence metrics\n",
    "                        if hasattr(self, '_last_trade_info') and self._last_trade_info:\n",
    "                            self._last_trade_info.update({\n",
    "                                'confidence': confidence,\n",
    "                                'entropy': metrics['entropy'],\n",
    "                                'all_probabilities': metrics['probabilities']\n",
    "                            })\n",
    "                else:\n",
    "                    logger.info(f\"Skipping trade for {pair} due to insufficient confidence\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in trading cycle for {pair}: {str(e)}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfidenceAnalyzer:\n",
    "    \"\"\"Analyzes the relationship between prediction confidence and trade outcomes.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_bins: int = 10):\n",
    "        self.num_bins = num_bins\n",
    "        self.trade_records = []\n",
    "        \n",
    "    def record_trade(self, trade_info: Dict):\n",
    "        \"\"\"Record a trade with its confidence metrics and outcome.\"\"\"\n",
    "        self.trade_records.append({\n",
    "            'confidence': trade_info['confidence'],\n",
    "            'entropy': trade_info['entropy'],\n",
    "            'action_probs': trade_info['all_probabilities'],\n",
    "            'pnl': trade_info['trade_pnl'],\n",
    "            'position_type': trade_info['position_type'],\n",
    "            'trade_duration': (trade_info['exit_time'] - trade_info['entry_time']).total_seconds() / 3600\n",
    "        })\n",
    "        \n",
    "    def analyze_confidence_levels(self) -> pd.DataFrame:\n",
    "        \"\"\"Analyze trade performance across different confidence levels.\"\"\"\n",
    "        if not self.trade_records:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        df = pd.DataFrame(self.trade_records)\n",
    "        \n",
    "        # Create confidence bins\n",
    "        df['confidence_bin'] = pd.qcut(df['confidence'], self.num_bins)\n",
    "        \n",
    "        # Analyze performance by confidence level\n",
    "        analysis = df.groupby('confidence_bin').agg({\n",
    "            'pnl': ['count', 'mean', 'std', lambda x: (x > 0).mean()],\n",
    "            'trade_duration': 'mean',\n",
    "            'entropy': 'mean'\n",
    "        })\n",
    "        \n",
    "        # Rename columns for clarity\n",
    "        analysis.columns = [\n",
    "            'num_trades', 'avg_pnl', 'pnl_std', 'win_rate', 'avg_duration', 'avg_entropy'\n",
    "        ]\n",
    "        \n",
    "        return analysis\n",
    "        \n",
    "    def get_optimal_threshold(self) -> float:\n",
    "        \"\"\"Calculate optimal confidence threshold based on historical performance.\"\"\"\n",
    "        if not self.trade_records:\n",
    "            return 0.6  # Default threshold\n",
    "            \n",
    "        df = pd.DataFrame(self.trade_records)\n",
    "        \n",
    "        # Calculate cumulative metrics at different thresholds\n",
    "        thresholds = np.linspace(0.4, 0.9, 50)\n",
    "        metrics = []\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            subset = df[df['confidence'] >= threshold]\n",
    "            if len(subset) < 20:  # Require minimum number of trades\n",
    "                continue\n",
    "                \n",
    "            metrics.append({\n",
    "                'threshold': threshold,\n",
    "                'num_trades': len(subset),\n",
    "                'win_rate': (subset['pnl'] > 0).mean(),\n",
    "                'avg_pnl': subset['pnl'].mean(),\n",
    "                'sharpe': subset['pnl'].mean() / (subset['pnl'].std() + 1e-10)\n",
    "            })\n",
    "            \n",
    "        if not metrics:\n",
    "            return 0.6\n",
    "            \n",
    "        # Find threshold that maximizes Sharpe ratio\n",
    "        metrics_df = pd.DataFrame(metrics)\n",
    "        optimal_threshold = metrics_df.loc[metrics_df['sharpe'].idxmax(), 'threshold']\n",
    "        \n",
    "        return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SB5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
