{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from trading.environments.forex_env2_flat import ForexTradingEnv, Actions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "class TransactionLogger:\n",
    "    \"\"\"Tracks detailed transaction data throughout an episode.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.transactions = []\n",
    "        \n",
    "    def log_step(\n",
    "        self,\n",
    "        step: int,\n",
    "        pre_step_price: float,\n",
    "        post_step_price: float,\n",
    "        action: str,\n",
    "        reward: float,\n",
    "        # realized_pnl: float,\n",
    "        # unrealized_pnl: float,\n",
    "        net_worth_chg: float,\n",
    "        position_type: str,\n",
    "        balance: float\n",
    "    ):\n",
    "        \"\"\"Log transaction data for each step.\"\"\"\n",
    "        self.transactions.append({\n",
    "            'step': step,\n",
    "            'pre_step_price': pre_step_price,\n",
    "            'post_step_price': post_step_price,\n",
    "            'action': action,\n",
    "            'reward': reward,\n",
    "            'net_worth_chg': net_worth_chg,\n",
    "            # 'realized_pnl': realized_pnl,\n",
    "            # 'unrealized_pnl': unrealized_pnl,\n",
    "            'position': position_type,\n",
    "            'balance': balance\n",
    "        })\n",
    "    \n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"Convert transaction log to pandas DataFrame.\"\"\"\n",
    "        df = pd.DataFrame(self.transactions)\n",
    "        \n",
    "        # Calculate price changes for analysis\n",
    "        if not df.empty:\n",
    "            df['price_change'] = df['pre_step_price'].diff()\n",
    "            df['price_change_pct'] = df['pre_step_price'].pct_change()\n",
    "            \n",
    "            # Calculate cumulative PnL\n",
    "            df['cumulative_realized_pnl'] = df['net_worth_chg'].cumsum()\n",
    "            \n",
    "        return df\n",
    "\n",
    "class EnvironmentDebugger:\n",
    "    \"\"\"Helper class to debug and visualize the Forex trading environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, env: ForexTradingEnv):\n",
    "        self.env = env\n",
    "        self.episode_history = []\n",
    "        self.current_episode = []\n",
    "        self.transaction_logger = TransactionLogger()\n",
    "        \n",
    "    def run_debug_episode(\n",
    "        self,\n",
    "        max_steps: int = 100,\n",
    "        action_strategy=\"random\",\n",
    "        custom_actions: List[int] = None\n",
    "    ):\n",
    "        \"\"\"Run debug episode with specified action strategy.\"\"\"\n",
    "        observation, info = self.env.reset()\n",
    "        self.current_episode = []\n",
    "        self.transaction_logger = TransactionLogger()\n",
    "        \n",
    "        print(\"\\n=== Starting New Debug Episode ===\")\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            # Get price before step (price at which we make decision)\n",
    "            pre_step_price = self.env.current_price\n",
    "            print(f\"Step: {step}, Price pre step: {pre_step_price}\")\n",
    "            \n",
    "            # Get action based on strategy\n",
    "            if custom_actions is not None and step < len(custom_actions):\n",
    "                action = custom_actions[step]\n",
    "            elif action_strategy == \"random\":\n",
    "                action = self.env.action_space.sample()\n",
    "            elif action_strategy == \"cycle\":\n",
    "                action = step % len(Actions)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown action strategy\")\n",
    "            \n",
    "            # Take step in environment\n",
    "            next_obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "            \n",
    "            # Now post_step_price is the current price after stepping\n",
    "            post_step_price = info['current_price']\n",
    "            net_worth_chg = info['net_worth_chg']\n",
    "            \n",
    "            # Log transaction data\n",
    "            self.transaction_logger.log_step(\n",
    "                step=step,\n",
    "                pre_step_price=pre_step_price,   # Price when decision was made\n",
    "                post_step_price=post_step_price, # Price used for PnL calculation\n",
    "                action=Actions(action).name,\n",
    "                reward=reward,\n",
    "                net_worth_chg= net_worth_chg,\n",
    "                # realized_pnl=info.get('trade_pnl', 0.0) if info.get('trade_closed', False) else 0.0,\n",
    "                # unrealized_pnl=info['unrealized_pnl'],\n",
    "                position_type=info['position_type'],\n",
    "                balance=info['balance']\n",
    "            )\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                print(f\"\\nEpisode ended after {step + 1} steps\")\n",
    "                break\n",
    "                \n",
    "            observation = next_obs\n",
    "            \n",
    "        # Print transaction log\n",
    "        # self._print_transaction_log()\n",
    "        \n",
    "        return self.transaction_logger.to_dataframe()\n",
    "    \n",
    "    def _print_transaction_log(self):\n",
    "        \"\"\"Print detailed transaction log.\"\"\"\n",
    "        df = self.transaction_logger.to_dataframe()\n",
    "        \n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "        \n",
    "        print(\"\\nDetailed Transaction Log:\")\n",
    "        print(\"Step | Pre-Price  | Post-Price | Action | Reward | Realized PnL | Unrealized PnL\")\n",
    "        print(\"-\" * 80)\n",
    "        for _, row in df.iterrows():\n",
    "            print(f\"{row['step']:4d} | {row['pre_step_price']:.5f} | {row['post_step_price']:.5f} | \"\n",
    "                  f\"{row['action']:<6} | {row['reward']:.5f} | {row['realized_pnl']:.5f} | \"\n",
    "                  f\"{row['unrealized_pnl']:.5f}\")\n",
    "            \n",
    "        # Print summary statistics\n",
    "        print(\"\\nSummary Statistics:\")\n",
    "        print(f\"Total Steps: {len(df)}\")\n",
    "        print(f\"Total Realized PnL: {df['realized_pnl'].sum():.5f}\")\n",
    "        print(f\"Final Unrealized PnL: {df['unrealized_pnl'].iloc[-1]:.5f}\")\n",
    "        print(f\"Final Balance: {df['balance'].iloc[-1]:.2f}\")\n",
    "        \n",
    "        pd.reset_option('display.max_rows')\n",
    "        pd.reset_option('display.float_format')\n",
    "    \n",
    "    def plot_transaction_analysis(self):\n",
    "        \"\"\"Create detailed plots of price movements, PnL, and actions.\"\"\"\n",
    "        df = self.transaction_logger.to_dataframe()\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "        \n",
    "        # Plot price and positions\n",
    "        ax1 = axes[0]\n",
    "        ax1.plot(df['step'], df['current_price'], label='Price', color='blue')\n",
    "        ax1.set_title('Price and Positions')\n",
    "        \n",
    "        # Add position markers\n",
    "        for idx, row in df.iterrows():\n",
    "            if row['action'] != 'NO_POSITION':\n",
    "                color = 'green' if row['action'] == 'LONG' else 'red'\n",
    "                ax1.axvline(x=row['step'], color=color, alpha=0.2)\n",
    "        \n",
    "        # Plot PnL\n",
    "        ax2 = axes[1]\n",
    "        ax2.plot(df['step'], df['realized_pnl'].cumsum(), label='Cumulative Realized PnL', color='green')\n",
    "        ax2.plot(df['step'], df['unrealized_pnl'], label='Unrealized PnL', color='blue', alpha=0.5)\n",
    "        ax2.set_title('PnL Analysis')\n",
    "        ax2.legend()\n",
    "        \n",
    "        # Plot rewards\n",
    "        ax3 = axes[2]\n",
    "        ax3.plot(df['step'], df['reward'], label='Reward', color='purple')\n",
    "        ax3.set_title('Rewards')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "pair = \"EUR_USD\"\n",
    "parquet_path = Path(\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h\") / f\"{pair}.parquet\"\n",
    "file_5min = '/Users/floriankockler/Downloads/EUR_USD_5T_indics_norm2.parquet'\n",
    "df = pd.read_parquet(file_5min)\n",
    "\n",
    "# Create environment\n",
    "env = ForexTradingEnv(\n",
    "    df=df,\n",
    "    pair=pair,\n",
    "    initial_balance=1_000_000,\n",
    "    sequence_length=10,\n",
    "    random_start=False\n",
    ")\n",
    "\n",
    "# Create debugger\n",
    "debugger = EnvironmentDebugger(env)\n",
    "\n",
    "# Run with custom actions for testing\n",
    "custom_actions = [\n",
    "    Actions.LONG.value,    # Open long\n",
    "    Actions.LONG.value,    # Hold long\n",
    "    Actions.SHORT.value,   # Switch to short\n",
    "    Actions.SHORT.value,   # Hold short\n",
    "    Actions.NO_POSITION.value  # Close position\n",
    "]\n",
    "\n",
    "transaction_df = debugger.run_debug_episode(\n",
    "    max_steps=len(custom_actions),\n",
    "    custom_actions=custom_actions\n",
    ")\n",
    "transaction_df\n",
    "# Plot analysis\n",
    "# debugger.plot_transaction_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = \"EUR_USD\"\n",
    "parquet_path = Path(\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h\") / f\"{pair}.parquet\"\n",
    "df = pd.read_parquet(parquet_path)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = \"EUR_USD\"\n",
    "parquet_path = Path(\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h\") / f\"{pair}.parquet\"\n",
    "df = pd.read_parquet(parquet_path)\n",
    "\n",
    "# Create environment\n",
    "env = ForexTradingEnv(\n",
    "    df=df,\n",
    "    pair=pair,\n",
    "    initial_balance=1_000_000,\n",
    "    sequence_length=10,\n",
    "    random_start=False  # Disable random start for debugging\n",
    ")\n",
    "\n",
    "# Create debugger\n",
    "debugger = EnvironmentDebugger(env)\n",
    "\n",
    "# Run debug episode with different action strategies\n",
    "print(\"\\nRunning episode with random actions...\")\n",
    "debugger.run_debug_episode(max_steps=50, action_strategy=\"random\")\n",
    "debugger.print_episode_summary()\n",
    "debugger.plot_episode_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# from datetime import datetime, timedelta\n",
    "# from pathlib import Path\n",
    "\n",
    "\n",
    "# # Add the project root to the Python path\n",
    "# project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "# if project_root not in sys.path:\n",
    "#     sys.path.append(project_root)\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "# from trading.environments.forex_env2_flat import ForexTradingEnv\n",
    "# from stable_baselines3.common.callbacks import EvalCallback\n",
    "# from stable_baselines3.common.monitor import Monitor\n",
    "# from data_management.dataset_manager import DatasetManager\n",
    "\n",
    "# pair = \"EUR_USD\"\n",
    "# # parquet_path = Path(\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h\") / f\"{pair}.parquet\"\n",
    "# # parquet_path = Path(\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h\") / f\"{pair}.parquet\"\n",
    "# norm_robust_path = Path('/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/normalized/eur_norm_robut.parquet')\n",
    "# eur_standard = Path('/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/EUR_USD.parquet')\n",
    "# df = pd.read_parquet(eur_standard)\n",
    "\n",
    "# dataset_manager = DatasetManager()\n",
    "# train_df, val_df, test_df = dataset_manager.split_dataset(df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "\n",
    "\n",
    "\n",
    "# saving_path = f'./logs/26nov/not_norm_flat/'\n",
    "# os.makedirs(saving_path, exist_ok=True)\n",
    "\n",
    "# def make_train_env():\n",
    "#     env = ForexTradingEnv(\n",
    "#         df=train_df,\n",
    "#         pair='EUR_USD',\n",
    "\n",
    "#     )\n",
    "#     env = Monitor(env)\n",
    "#     env = DummyVecEnv([lambda: env])\n",
    "#     env = VecNormalize(env, norm_obs=True, norm_reward=True)\n",
    "#     return env\n",
    "\n",
    "# def make_eval_env():\n",
    "#     env = ForexTradingEnv(\n",
    "\n",
    "#         df=val_df,\n",
    "#         pair='EUR_USD',\n",
    "#         # resample_interval='1h'\n",
    "#     )\n",
    "#     env = Monitor(env)\n",
    "#     env = DummyVecEnv([lambda: env])\n",
    "#     env = VecNormalize(env, norm_obs=True, norm_reward=False)\n",
    "#     env.training = False\n",
    "#     return env\n",
    "\n",
    "# train_env = make_train_env()\n",
    "# eval_env = make_eval_env()\n",
    "# eval_callback = EvalCallback(\n",
    "#     eval_env,\n",
    "#     best_model_save_path=saving_path,\n",
    "#     log_path=saving_path,\n",
    "#     eval_freq=100_000,  # Adjust as needed\n",
    "#     n_eval_episodes=5,\n",
    "#     deterministic=True,\n",
    "#     render=False\n",
    "# )\n",
    "\n",
    "# model = PPO(\n",
    "#     'MlpPolicy',\n",
    "#     train_env,\n",
    "#     verbose=0,\n",
    "#     tensorboard_log=f'{saving_path}tensorboard/',\n",
    "# )\n",
    "\n",
    "# model.learn(\n",
    "#     total_timesteps=5_000_000,  # Adjust as needed\n",
    "#     callback=eval_callback\n",
    "# )\n",
    "\n",
    "# model.save(f'{saving_path}best_model.zip')\n",
    "# train_env.save(f'{saving_path}vec_normalize.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, sys\n",
    "# project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "# if project_root not in sys.path:\n",
    "#     sys.path.append(project_root)\n",
    "# from trading.environments.forex_env2_flat import ForexTradingEnv, Actions\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "# import matplotlib.pyplot as plt\n",
    "# from pprint import pprint\n",
    "\n",
    "# class EnvironmentDebugger:\n",
    "#     \"\"\"Helper class to debug and visualize the Forex trading environment.\"\"\"\n",
    "    \n",
    "#     def __init__(self, env: ForexTradingEnv):\n",
    "#         self.env = env\n",
    "#         self.episode_history = []\n",
    "#         self.current_episode = []\n",
    "        \n",
    "#     def run_debug_episode(self, max_steps: int = 100, action_strategy=\"random\"):\n",
    "#         \"\"\"Run a debug episode with specified action strategy.\"\"\"\n",
    "#         # Handle the reset tuple return (observation, info)\n",
    "#         observation, info = self.env.reset()\n",
    "#         self.current_episode = []\n",
    "        \n",
    "#         print(\"\\n=== Starting New Debug Episode ===\")\n",
    "#         print(f\"Initial observation shape: {observation.shape}\")\n",
    "#         print(\"\\nInitial Info:\")\n",
    "#         pprint(info)\n",
    "        \n",
    "#         # Print initial state\n",
    "#         self._print_step_info(observation, None, 0, info, 0)\n",
    "        \n",
    "#         for step in range(max_steps):\n",
    "#             # Get action based on strategy\n",
    "#             if action_strategy == \"random\":\n",
    "#                 action = self.env.action_space.sample()\n",
    "#             elif action_strategy == \"cycle\":\n",
    "#                 action = step % len(Actions)\n",
    "#             else:\n",
    "#                 raise ValueError(\"Unknown action strategy\")\n",
    "            \n",
    "#             # Take step in environment and unpack return values\n",
    "#             next_obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "            \n",
    "#             # Store step information\n",
    "#             step_data = {\n",
    "#                 'step': step,\n",
    "#                 'action': Actions(action).name,\n",
    "#                 'observation': next_obs.copy(),\n",
    "#                 'reward': reward,\n",
    "#                 'info': info.copy()\n",
    "#             }\n",
    "#             self.current_episode.append(step_data)\n",
    "            \n",
    "#             # Print step information\n",
    "#             self._print_step_info(next_obs, action, reward, info, step + 1)\n",
    "            \n",
    "#             if terminated or truncated:\n",
    "#                 print(f\"\\nEpisode ended after {step + 1} steps\")\n",
    "#                 print(\"Final Info:\")\n",
    "#                 pprint(info)\n",
    "#                 break\n",
    "                \n",
    "#             observation = next_obs\n",
    "        \n",
    "#         self.episode_history.append(self.current_episode)\n",
    "        \n",
    "#     def _print_step_info(self, obs, action, reward, info, step):\n",
    "#         \"\"\"Print detailed information about the current step.\"\"\"\n",
    "#         print(f\"\\nStep {step}\")\n",
    "#         print(\"-\" * 50)\n",
    "        \n",
    "#         # Print action if not initial step\n",
    "#         if action is not None:\n",
    "#             print(f\"Action taken: {Actions(action).name}\")\n",
    "#             print(f\"Reward received: {reward:.6f}\")\n",
    "        \n",
    "#         # Print observation components\n",
    "#         market_size = self.env.sequence_length * self.env.market_features\n",
    "#         print(\"\\nObservation breakdown:\")\n",
    "#         print(f\"Market features shape: {obs[:market_size].shape}\")\n",
    "#         print(f\"Position info: {obs[market_size:]}\")  # Balance and position direction\n",
    "        \n",
    "#         # Print current market data\n",
    "#         current_timestamp = info.get('timestamp', None)\n",
    "#         current_price = info.get('current_price', None)\n",
    "#         if current_timestamp and current_price:\n",
    "#             print(f\"\\nCurrent Time: {current_timestamp}\")\n",
    "#             print(f\"Current Price: {current_price}\")\n",
    "        \n",
    "#         # Print trading state\n",
    "#         position_type = info.get('position_type', 'none')\n",
    "#         balance = info.get('balance', 0.0)\n",
    "#         unrealized_pnl = info.get('unrealized_pnl', 0.0)\n",
    "        \n",
    "#         print(f\"\\nTrading State:\")\n",
    "#         print(f\"Position: {position_type}\")\n",
    "#         print(f\"Balance: ${balance:,.2f}\")\n",
    "#         print(f\"Unrealized PnL: ${unrealized_pnl:,.2f}\")\n",
    "        \n",
    "#         print(\"-\" * 50)\n",
    "    \n",
    "#     def plot_episode_results(self):\n",
    "#         \"\"\"Plot key metrics from the most recent episode.\"\"\"\n",
    "#         if not self.current_episode:\n",
    "#             print(\"No episode data to plot\")\n",
    "#             return\n",
    "        \n",
    "#         # Extract data\n",
    "#         steps = [data['step'] for data in self.current_episode]\n",
    "#         rewards = [data['reward'] for data in self.current_episode]\n",
    "#         balances = [data['info']['balance'] for data in self.current_episode]\n",
    "#         prices = [data['info']['current_price'] for data in self.current_episode]\n",
    "        \n",
    "#         # Create plot\n",
    "#         fig, axes = plt.subplots(3, 1, figsize=(12, 12))\n",
    "        \n",
    "#         # Plot rewards\n",
    "#         axes[0].plot(steps, rewards, label='Reward', color='blue')\n",
    "#         axes[0].set_title('Rewards per Step')\n",
    "#         axes[0].set_xlabel('Step')\n",
    "#         axes[0].set_ylabel('Reward')\n",
    "#         axes[0].grid(True)\n",
    "        \n",
    "#         # Plot balance\n",
    "#         axes[1].plot(steps, balances, label='Account Balance', color='green')\n",
    "#         axes[1].set_title('Account Balance')\n",
    "#         axes[1].set_xlabel('Step')\n",
    "#         axes[1].set_ylabel('Balance')\n",
    "#         axes[1].grid(True)\n",
    "        \n",
    "#         # Plot price\n",
    "#         axes[2].plot(steps, prices, label='Price', color='red')\n",
    "#         axes[2].set_title('Price Movement')\n",
    "#         axes[2].set_xlabel('Step')\n",
    "#         axes[2].set_ylabel('Price')\n",
    "#         axes[2].grid(True)\n",
    "        \n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "        \n",
    "#     def print_episode_summary(self):\n",
    "#         \"\"\"Print summary statistics for the most recent episode.\"\"\"\n",
    "#         if not self.current_episode:\n",
    "#             print(\"No episode data to summarize\")\n",
    "#             return\n",
    "            \n",
    "#         first_step = self.current_episode[0]['info']\n",
    "#         last_step = self.current_episode[-1]['info']\n",
    "        \n",
    "#         print(\"\\n=== Episode Summary ===\")\n",
    "#         print(f\"Number of steps: {len(self.current_episode)}\")\n",
    "#         print(f\"Initial balance: ${first_step['balance']:,.2f}\")\n",
    "#         print(f\"Final balance: ${last_step['balance']:,.2f}\")\n",
    "#         print(f\"Total PnL: ${last_step['total_pnl']:,.2f}\")\n",
    "#         print(f\"Total trades: {last_step['total_trades']}\")\n",
    "#         if last_step['total_trades'] > 0:\n",
    "#             print(f\"Win rate: {last_step['win_rate']:.2%}\")\n",
    "#         print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SB5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
