{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from data_management.dataset_manager import DatasetManager\n",
    "from trading.model_manager import ModelManager\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "\n",
    "project_dir = Path.cwd() / \"forex_models\"  # Create in current working directory\n",
    "project_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 1. Load and prepare data\n",
    "dataset_manager = DatasetManager()\n",
    "\n",
    "pair = \"EUR_USD\"\n",
    "parquet_path = Path(\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h\") / f\"{pair}.parquet\"\n",
    "df = pd.read_parquet(parquet_path)\n",
    "\n",
    "\n",
    "train_df, val_df, test_df = dataset_manager.split_dataset(df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "\n",
    "print(f\"Data splits:\")\n",
    "print(f\"Training: {len(train_df)} samples\")\n",
    "print(f\"Validation: {len(val_df)} samples\")\n",
    "print(f\"Test: {len(test_df)} samples\")\n",
    "\n",
    "# 3. Initialize model manager\n",
    "model_manager = ModelManager(\n",
    "    base_path=str(project_dir),\n",
    "    n_envs=1,\n",
    "    verbose=0\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# 5. Train model\n",
    "\n",
    "print(\"\\nStarting model training...\")\n",
    "model, metrics = model_manager.train_model(\n",
    "    df=train_df,\n",
    "    pair=pair,\n",
    "    total_timesteps=1_000_000,  # Start with smaller number for testing\n",
    "    eval_freq=50_000\n",
    ")\n",
    "\n",
    "# 6. Evaluate on validation set\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "val_metrics = model_manager.evaluate_model(\n",
    "    model=model,\n",
    "    df=val_df,\n",
    "    pair=pair,\n",
    "    n_evaluations=5\n",
    ")\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"Total PnL: {val_metrics.total_pnl:.2f}\")\n",
    "print(f\"Win Rate: {val_metrics.win_rate:.2%}\")\n",
    "print(f\"Sharpe Ratio: {val_metrics.sharpe_ratio:.2f}\")\n",
    "print(f\"Max Drawdown: {val_metrics.max_drawdown:.2%}\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "from trading.environments.forex_env import ForexTradingEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Training mainly to check if ENV works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "from trading.environments.forex_env2 import ForexTradingEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from data_management.dataset_manager import DatasetManager\n",
    "\n",
    "pair = \"EUR_USD\"\n",
    "# parquet_path = Path(\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h\") / f\"{pair}.parquet\"\n",
    "# parquet_path = Path(\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h\") / f\"{pair}.parquet\"\n",
    "norm_robust_path = Path('/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/normalized/eur_norm_robut.parquet')\n",
    "eur_standard = Path('/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/EUR_USD.parquet')\n",
    "df = pd.read_parquet(eur_standard)\n",
    "\n",
    "dataset_manager = DatasetManager()\n",
    "train_df, val_df, test_df = dataset_manager.split_dataset(df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "\n",
    "\n",
    "\n",
    "saving_path = f'./logs/22nov/not_norm/'\n",
    "os.makedirs(saving_path, exist_ok=True)\n",
    "\n",
    "def make_train_env():\n",
    "    env = ForexTradingEnv(\n",
    "        df=train_df,\n",
    "        pair='EUR_USD',\n",
    "\n",
    "    )\n",
    "    env = Monitor(env)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    env = VecNormalize(env, norm_obs=True, norm_reward=True)\n",
    "    return env\n",
    "\n",
    "def make_eval_env():\n",
    "    env = ForexTradingEnv(\n",
    "\n",
    "        df=val_df,\n",
    "        pair='EUR_USD',\n",
    "        # resample_interval='1h'\n",
    "    )\n",
    "    env = Monitor(env)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    env = VecNormalize(env, norm_obs=True, norm_reward=False)\n",
    "    env.training = False\n",
    "    return env\n",
    "\n",
    "train_env = make_train_env()\n",
    "eval_env = make_eval_env()\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=saving_path,\n",
    "    log_path=saving_path,\n",
    "    eval_freq=100_000,  # Adjust as needed\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = PPO(\n",
    "    'MultiInputPolicy',\n",
    "    train_env,\n",
    "    verbose=0,\n",
    "    tensorboard_log=f'{saving_path}tensorboard/',\n",
    ")\n",
    "\n",
    "model.learn(\n",
    "    total_timesteps=5_000_000,  # Adjust as needed\n",
    "    callback=eval_callback\n",
    ")\n",
    "\n",
    "model.save(f'{saving_path}best_model.zip')\n",
    "train_env.save(f'{saving_path}vec_normalize.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "norm_robust_path = Path('/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/normalized/eur_norm_robut.parquet')\n",
    "eur_standard = Path('/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/EUR_USD.parquet')\n",
    "df = pd.read_parquet(eur_standard)\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "from trading.environments.env_old import TradingEnvSimple_V2\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from data_management.dataset_manager import DatasetManager\n",
    "\n",
    "pair = \"EUR_USD\"\n",
    "# parquet_path = Path(\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h\") / f\"{pair}.parquet\"\n",
    "# parquet_path = Path(\"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h\") / f\"{pair}.parquet\"\n",
    "norm_robust_path = Path('/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/normalized/eur_norm_robut.parquet')\n",
    "eur_standard = Path('/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/EUR_USD.parquet')\n",
    "df = pd.read_parquet(eur_standard)\n",
    "\n",
    "\n",
    "dataset_manager = DatasetManager()\n",
    "train_df, val_df, test_df = dataset_manager.split_dataset(df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "train_df = train_df.reset_index()\n",
    "val_df = val_df.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "saving_path = f'./logs/25nov/old_env/'\n",
    "os.makedirs(saving_path, exist_ok=True)\n",
    "\n",
    "def make_train_env():\n",
    "    env = TradingEnvSimple_V2(\n",
    "        df=train_df,\n",
    "\n",
    "\n",
    "    )\n",
    "    env = Monitor(env)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    env = VecNormalize(env, norm_obs=True, norm_reward=True)\n",
    "    return env\n",
    "\n",
    "def make_eval_env():\n",
    "    env = TradingEnvSimple_V2(\n",
    "\n",
    "        df=val_df,\n",
    "\n",
    "        # resample_interval='1h'\n",
    "    )\n",
    "    env = Monitor(env)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    env = VecNormalize(env, norm_obs=True, norm_reward=False)\n",
    "    env.training = False\n",
    "    return env\n",
    "\n",
    "train_env = make_train_env()\n",
    "eval_env = make_eval_env()\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=saving_path,\n",
    "    log_path=saving_path,\n",
    "    eval_freq=100_000,  # Adjust as needed\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = PPO(\n",
    "    'MlpPolicy',\n",
    "    train_env,\n",
    "    verbose=0,\n",
    "    tensorboard_log=f'{saving_path}tensorboard/',\n",
    ")\n",
    "\n",
    "model.learn(\n",
    "    total_timesteps=5_000_000,  # Adjust as needed\n",
    "    callback=eval_callback\n",
    ")\n",
    "\n",
    "model.save(f'{saving_path}best_model.zip')\n",
    "train_env.save(f'{saving_path}vec_normalize.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os, sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from data_management.dataset_manager import DatasetManager\n",
    "from trading.model_manager import ModelManager\n",
    "from trading.agents.evaluate_model import ModelEvaluator, TradeLedger\n",
    "from pathlib import Path\n",
    "from trading.environments.forex_env import ForexTradingEnv\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv, VecNormalize\n",
    "from stable_baselines3 import PPO\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "eval_path = Path(\"model_evaluations\")\n",
    "eval_path.mkdir(exist_ok=True)\n",
    "evaluator = ModelEvaluator(base_path=eval_path)\n",
    "\n",
    "\n",
    "dataset_manager = DatasetManager()\n",
    "pair = \"EUR_USD\"\n",
    "df = dataset_manager.load_parquet_dataset(pair)\n",
    "train_df, val_df, test_df = dataset_manager.split_dataset(df)\n",
    "\n",
    "def load_model_for_evaluation(model_path: Path, env_path: Path) -> Tuple[PPO, VecNormalize]:\n",
    "    \"\"\"\n",
    "    Load a trained model and its normalization parameters.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the saved model\n",
    "        env_path: Path to the saved VecNormalize stats\n",
    "    \"\"\"\n",
    "    # Create a dummy environment (required for loading)\n",
    "    def make_env():\n",
    "        def _init():\n",
    "            env = ForexTradingEnv(\n",
    "                df=test_df,  # Empty DataFrame for now\n",
    "                pair=\"EUR_USD\"\n",
    "            )\n",
    "            return env\n",
    "        return _init\n",
    "    \n",
    "    # Create vectorized environment\n",
    "    vec_env = DummyVecEnv([make_env()])\n",
    "    \n",
    "    # Load the saved normalization statistics\n",
    "    vec_env = VecNormalize.load(\n",
    "        env_path,\n",
    "        vec_env\n",
    "    )\n",
    "    \n",
    "    # Don't update normalization statistics during evaluation\n",
    "    vec_env.training = False\n",
    "    vec_env.norm_reward = False\n",
    "    \n",
    "    # Load the model\n",
    "    model = PPO.load(model_path)\n",
    "    \n",
    "    # Set the correct environment\n",
    "    model.set_env(vec_env)\n",
    "    \n",
    "    return model, vec_env\n",
    "\n",
    "model, vec_env = load_model_for_evaluation(\n",
    "    model_path= Path('/Users/floriankockler/Code/GitHub.nosync/ai6-gcp-bot/forex_trading_system/notebooks/logs/20nov/best_model'), \n",
    "    env_path= Path('/Users/floriankockler/Code/GitHub.nosync/ai6-gcp-bot/forex_trading_system/notebooks/logs/20nov/vec_normalize.pkl')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from data_management.dataset_manager import DatasetManager\n",
    "from trading.model_manager import ModelManager\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "from trading.agents.evaluate_model import ModelEvaluator, TradeLedger\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Create evaluation directory\n",
    "result_dir = Path(\"model_evaluation\") / f\"EUR_USD_eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "result_dir.mkdir(parents=True)\n",
    "\n",
    "# Initialize evaluator \n",
    "evaluator = ModelEvaluator(base_path=Path(\"model_evaluation\"))\n",
    "\n",
    "# Evaluate model\n",
    "metrics, ledger = evaluator._evaluate_single_dataset(\n",
    "    model=model,\n",
    "    df=test_df,\n",
    "    pair=\"EUR_USD\",\n",
    "    save_dir=result_dir\n",
    ")\n",
    "\n",
    "# Get trade analysis\n",
    "trades_df = ledger.to_dataframe()\n",
    "trades_df.to_csv(result_dir / \"trades.csv\")\n",
    "\n",
    "print(f\"\\nEvaluation Results:\")\n",
    "print(f\"Total Trades: {len(trades_df)}\")\n",
    "print(f\"Win Rate: {metrics['win_rate']:.2%}\")\n",
    "print(f\"Total PnL: {metrics['total_pnl']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Out reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor reward distributions\n",
    "#! env not unwraped\n",
    "rewards = []\n",
    "realized_pnls = []\n",
    "unrealized_pnls = []\n",
    "\n",
    "for episode in range(10):\n",
    "    obs = train_env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = model.predict(obs, deterministic=True)[0]\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        rewards.append(reward)\n",
    "        if info.get('trade_closed'):\n",
    "            realized_pnls.append(info['trade_pnl'])\n",
    "        if info.get('unrealized_pnl'):\n",
    "            unrealized_pnls.append(info['unrealized_pnl'])\n",
    "\n",
    "print(f\"Reward stats:\")\n",
    "print(f\"Mean: {np.mean(rewards):.4f}\")\n",
    "print(f\"Std: {np.std(rewards):.4f}\")\n",
    "print(f\"Min: {np.min(rewards):.4f}\")\n",
    "print(f\"Max: {np.max(rewards):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward distribution monitoring\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def monitor_rewards(model, env, n_episodes=10):\n",
    "    \"\"\"\n",
    "    Monitor reward distributions and trading behavior with proper env unwrapping.\n",
    "    \"\"\"\n",
    "    # Unwrap to get the base environment\n",
    "    if hasattr(env, 'envs'):\n",
    "        # VecEnv unwrapping\n",
    "        base_env = env.envs[0]\n",
    "        if hasattr(base_env, 'env'):\n",
    "            # Possible Monitor wrapper\n",
    "            base_env = base_env.env\n",
    "        if hasattr(base_env, 'env'):\n",
    "            # Possible other wrappers\n",
    "            base_env = base_env.env\n",
    "    else:\n",
    "        base_env = env\n",
    "        \n",
    "    # Storage for metrics\n",
    "    metrics = {\n",
    "        'rewards': [],\n",
    "        'realized_pnls': [],\n",
    "        'unrealized_pnls': [],\n",
    "        'trade_durations': [],\n",
    "        'drawdowns': [],\n",
    "        'balance_trajectory': []\n",
    "    }\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        episode_rewards = []\n",
    "        \n",
    "        print(f\"\\nStarting episode {episode + 1}/{n_episodes}\")\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            \n",
    "            # Store raw reward\n",
    "            metrics['rewards'].append(reward[0])  # Unwrap from vectorized form\n",
    "            \n",
    "            # Get info from base environment\n",
    "            metrics['balance_trajectory'].append(base_env.balance)\n",
    "            \n",
    "            if base_env.position is not None:\n",
    "                unrealized_pnl = base_env._calculate_pnl(\n",
    "                    base_env.position.type,\n",
    "                    base_env.position.entry_price,\n",
    "                    base_env.df.iloc[base_env.current_step]['close'],\n",
    "                    base_env.position.size\n",
    "                )\n",
    "                metrics['unrealized_pnls'].append(unrealized_pnl)\n",
    "            \n",
    "            # Store trade information when a trade is closed\n",
    "            info = info[0] if isinstance(info, tuple) else info  # Unwrap info\n",
    "            # Store available metrics from info dict\n",
    "            metrics['balances'].append(info['balance'])\n",
    "            metrics['total_pnl'].append(info['total_pnl'])\n",
    "            metrics['unrealized_pnl'].append(info['unrealized_pnl'])\n",
    "            metrics['win_rates'].append(info['win_rate'])\n",
    "            metrics['drawdowns'].append(info['drawdown'])\n",
    "        \n",
    "        # Episode summary\n",
    "        print(f\"Episode {episode + 1} completed:\")\n",
    "        print(f\"Final Balance: {info['balance']:.2f}\")\n",
    "        print(f\"Total PnL: {info['total_pnl']:.2f}\")\n",
    "        print(f\"Win Rate: {info['win_rate']:.2%}\")\n",
    "        print(f\"Max Drawdown: {info['drawdown']:.2%}\")\n",
    "\n",
    "    # Create analysis plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Reward distribution\n",
    "    sns.histplot(metrics['rewards'], bins=50, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Reward Distribution')\n",
    "    axes[0, 0].set_xlabel('Reward')\n",
    "    \n",
    "    # PnL trajectory\n",
    "    axes[0, 1].plot(metrics['total_pnl'])\n",
    "    axes[0, 1].set_title('Total PnL Trajectory')\n",
    "    axes[0, 1].set_xlabel('Step')\n",
    "    axes[0, 1].set_ylabel('PnL')\n",
    "    \n",
    "    # Balance trajectory\n",
    "    axes[1, 0].plot(metrics['balances'])\n",
    "    axes[1, 0].set_title('Balance Trajectory')\n",
    "    axes[1, 0].set_xlabel('Step')\n",
    "    axes[1, 0].set_ylabel('Balance')\n",
    "    \n",
    "    # Win rate trajectory\n",
    "    axes[1, 1].plot(metrics['win_rates'])\n",
    "    axes[1, 1].set_title('Win Rate Trajectory')\n",
    "    axes[1, 1].set_xlabel('Step')\n",
    "    axes[1, 1].set_ylabel('Win Rate')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print statistics\n",
    "    print(\"\\nReward Statistics:\")\n",
    "    print(f\"Mean Reward: {np.mean(metrics['rewards']):.4f}\")\n",
    "    print(f\"Std Reward: {np.std(metrics['rewards']):.4f}\")\n",
    "    print(f\"Min Reward: {np.min(metrics['rewards']):.4f}\")\n",
    "    print(f\"Max Reward: {np.max(metrics['rewards']):.4f}\")\n",
    "    \n",
    "    print(\"\\nTrading Statistics:\")\n",
    "    print(f\"Final Total PnL: {metrics['total_pnl'][-1]:.2f}\")\n",
    "    print(f\"Final Win Rate: {metrics['win_rates'][-1]:.2%}\")\n",
    "    print(f\"Max Drawdown: {max(metrics['drawdowns']):.2%}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "eval_freq = 50000\n",
    "total_timesteps = 100_0000\n",
    "\n",
    "model_dir = ''\n",
    "vec_normalize_path = ''\n",
    "model = PPO.load(model_dir)\n",
    "\n",
    "# Create and normalize evaluation environment\n",
    "def make_env():\n",
    "    return ForexTradingEnv(\n",
    "        df=test_df,  # Your test DataFrame\n",
    "        pair='EUR_USD',\n",
    "        initial_balance=1_000_000.0,\n",
    "        trade_size=100_000.0,\n",
    "        random_start=False\n",
    "    )\n",
    "\n",
    "# Create vectorized environment\n",
    "env = DummyVecEnv([make_env])\n",
    "env = VecNormalize(\n",
    "    env,\n",
    "    norm_obs=True,\n",
    "    norm_reward=False,  # Disable reward normalization for evaluation\n",
    "\n",
    ")\n",
    "\n",
    "# Load saved normalization stats\n",
    "env = VecNormalize.load(vec_normalize_path, env)\n",
    "env.training = False  # Disable training mode\n",
    "env.norm_reward = False  # Make sure reward normalization is disabled\n",
    "\n",
    "# Now run the monitoring\n",
    "reward_metrics = monitor_rewards(\n",
    "    model=model,\n",
    "    env=env,\n",
    "    n_episodes=1  # Number of episodes to evaluate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the model incl using trade ledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from trading.agents.evaluate_model import ModelEvaluator\n",
    "from trading.agents.trade_ledger import TradeLedger\n",
    "from trading.environments.forex_env import ForexTradingEnv\n",
    "from data_management.dataset_manager import DatasetManager\n",
    "from trading.model_manager import ModelManager\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "# Setup paths\n",
    "eval_path = Path(\"model_evaluation\")\n",
    "eval_path.mkdir(exist_ok=True)\n",
    "\n",
    "dataset_manager = DatasetManager()\n",
    "train_df, val_df, test_df = dataset_manager.split_dataset(df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "\n",
    "\n",
    "\n",
    "saving_path = f'./logs/20nov/'\n",
    "\n",
    "def create_eval_env(df: pd.DataFrame, pair: str) -> VecNormalize:\n",
    "    \"\"\"Create and normalize evaluation environment.\"\"\"\n",
    "    def make_env():\n",
    "        return ForexTradingEnv(\n",
    "            df=df,\n",
    "            pair='EUR_USD',\n",
    "            initial_balance=1_000_000.0,\n",
    "            trade_size=100_000.0,\n",
    "            random_start=False  # Important for evaluation\n",
    "        )\n",
    "    \n",
    "    env = DummyVecEnv([make_env])\n",
    "    env = VecNormalize(\n",
    "        env,\n",
    "        norm_obs=True,\n",
    "        norm_reward=False,\n",
    "     \n",
    "    )\n",
    "    return env\n",
    "\n",
    "# Setup paths\n",
    "# model_dir = Path(f\"{saving_path}/best_model.zip\")\n",
    "eval_path = Path(\"model_evaluation\")\n",
    "eval_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = ModelEvaluator(base_path=eval_path)\n",
    "\n",
    "# Load model and normalization\n",
    "pair = \"EUR_USD\"\n",
    "model_path = f\"{saving_path}/best_model.zip\"\n",
    "vec_normalize_path = f\"{saving_path}/best_model.zp\"\n",
    "\n",
    "# Load the model\n",
    "model = PPO.load(model_path)\n",
    "\n",
    "# Create evaluation environment and load normalization stats\n",
    "eval_env = create_eval_env(test_df, pair)\n",
    "eval_env = VecNormalize.load(vec_normalize_path, eval_env)\n",
    "# Important: don't update normalization stats during evaluation\n",
    "eval_env.training = False\n",
    "\n",
    "\n",
    "# Run evaluation\n",
    "print(\"Running model evaluation...\")\n",
    "results, trade_ledger = evaluator.evaluate_model(\n",
    "    model=model,\n",
    "    env=eval_env,  # Pass the normalized environment\n",
    "    df=test_df,\n",
    "    pair=pair,\n",
    "    version_id=\"v1\"\n",
    ")\n",
    "\n",
    "# Save detailed results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_dir = eval_path / f\"{pair}_evaluation_20nov_{timestamp}\"\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save trade log to Excel\n",
    "output_file = results_dir / \"trade_analysis.xlsx\"\n",
    "trade_ledger['test'].export_to_excel(output_file)\n",
    "\n",
    "# Convert trade ledger to DataFrame for analysis\n",
    "trades_df = trade_ledger['test'].to_dataframe()\n",
    "\n",
    "# Print summary metrics\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(f\"Total Trades: {len(trades_df)}\")\n",
    "print(f\"Win Rate: {(trades_df['pnl'] > 0).mean():.2%}\")\n",
    "print(f\"Total PnL: {trades_df['pnl'].sum():.2f}\")\n",
    "print(f\"Average PnL per Trade: {trades_df['pnl'].mean():.2f}\")\n",
    "print(f\"Sharpe Ratio: {results['test']['sharpe_ratio']:.2f}\")\n",
    "print(f\"Max Drawdown: {results['test']['max_drawdown']:.2%}\")\n",
    "\n",
    "# Analyze trades by session\n",
    "session_analysis = trades_df.groupby('session').agg({\n",
    "    'pnl': ['count', 'mean', 'sum'],\n",
    "    'duration': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nSession Analysis:\")\n",
    "display(session_analysis)\n",
    "\n",
    "# Analyze trades by holding period\n",
    "duration_bins = [0, 1, 4, 8, 24, float('inf')]\n",
    "duration_labels = ['0-1h', '1-4h', '4-8h', '8-24h', '>24h']\n",
    "trades_df['duration_category'] = pd.cut(\n",
    "    trades_df['duration'], \n",
    "    bins=duration_bins, \n",
    "    labels=duration_labels\n",
    ")\n",
    "\n",
    "duration_analysis = trades_df.groupby('duration_category').agg({\n",
    "    'pnl': ['count', 'mean', lambda x: (x > 0).mean()],\n",
    "    'duration': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nDuration Analysis:\")\n",
    "display(duration_analysis)\n",
    "\n",
    "# Save trades to CSV\n",
    "trades_df.to_csv(results_dir / \"trades.csv\", index=True)\n",
    "\n",
    "# Create visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Cumulative PnL\n",
    "cumulative_pnl = trades_df['pnl'].cumsum()\n",
    "axes[0, 0].plot(cumulative_pnl.index, cumulative_pnl.values)\n",
    "axes[0, 0].set_title('Cumulative PnL')\n",
    "axes[0, 0].set_xlabel('Trade Number')\n",
    "axes[0, 0].set_ylabel('Cumulative PnL')\n",
    "\n",
    "# PnL Distribution\n",
    "sns.histplot(data=trades_df, x='pnl', bins=50, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('PnL Distribution')\n",
    "\n",
    "# Win Rate by Session\n",
    "session_win_rates = trades_df.groupby('session')['pnl'].apply(lambda x: (x > 0).mean())\n",
    "session_win_rates.plot(kind='bar', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Win Rate by Session')\n",
    "axes[1, 0].set_ylabel('Win Rate')\n",
    "\n",
    "# Trade Duration Distribution\n",
    "sns.histplot(data=trades_df, x='duration', bins=50, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Trade Duration Distribution')\n",
    "axes[1, 1].set_xlabel('Duration (hours)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / \"analysis_plots.png\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nResults saved to: {results_dir}\")\n",
    "print(f\"Trade log: {output_file}\")\n",
    "print(f\"Trades CSV: {results_dir / 'trades.csv'}\")\n",
    "print(f\"Analysis plots: {results_dir / 'analysis_plots.png'}\")\n",
    "\n",
    "# Close environment\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os, sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from data_management.dataset_manager import DatasetManager\n",
    "from trading.model_manager import ModelManager\n",
    "from trading.agents.evaluate_model import ModelEvaluator, TradeLedger\n",
    "from pathlib import Path\n",
    "from trading.environments.forex_env import ForexTradingEnv\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv, VecNormalize\n",
    "from stable_baselines3 import PPO\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "eval_path = Path(\"model_evaluations\")\n",
    "eval_path.mkdir(exist_ok=True)\n",
    "evaluator = ModelEvaluator(base_path=eval_path)\n",
    "\n",
    "\n",
    "dataset_manager = DatasetManager()\n",
    "pair = \"EUR_USD\"\n",
    "df = dataset_manager.load_parquet_dataset(pair)\n",
    "train_df, val_df, test_df = dataset_manager.split_dataset(df)\n",
    "\n",
    "def load_model_for_evaluation(model_path: Path, env_path: Path) -> Tuple[PPO, VecNormalize]:\n",
    "    \"\"\"\n",
    "    Load a trained model and its normalization parameters.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the saved model\n",
    "        env_path: Path to the saved VecNormalize stats\n",
    "    \"\"\"\n",
    "    # Create a dummy environment (required for loading)\n",
    "    def make_env():\n",
    "        def _init():\n",
    "            env = ForexTradingEnv(\n",
    "                df=test_df,  # Empty DataFrame for now\n",
    "                pair=\"EUR_USD\"\n",
    "            )\n",
    "            return env\n",
    "        return _init\n",
    "    \n",
    "    # Create vectorized environment\n",
    "    vec_env = DummyVecEnv([make_env()])\n",
    "    \n",
    "    # Load the saved normalization statistics\n",
    "    vec_env = VecNormalize.load(\n",
    "        env_path,\n",
    "        vec_env\n",
    "    )\n",
    "    \n",
    "    # Don't update normalization statistics during evaluation\n",
    "    vec_env.training = False\n",
    "    vec_env.norm_reward = False\n",
    "    \n",
    "    # Load the model\n",
    "    model = PPO.load(model_path)\n",
    "    \n",
    "    # Set the correct environment\n",
    "    model.set_env(vec_env)\n",
    "    \n",
    "    return model, vec_env\n",
    "\n",
    "load_model_for_evaluation(\n",
    "    model_path= Path('/Users/floriankockler/Code/GitHub.nosync/ai6-gcp-bot/forex_trading_system/notebooks/forex_models/deployed/EUR_USD/model.zip'), \n",
    "    env_path= Path('/Users/floriankockler/Code/GitHub.nosync/ai6-gcp-bot/forex_trading_system/notebooks/forex_models/deployed/EUR_USD/vec_normalize.pkl')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os, sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from data_management.dataset_manager import DatasetManager\n",
    "from trading.model_manager import ModelManager\n",
    "\n",
    "# Import the evaluation code\n",
    "from trading.agents.evaluate_model import ModelEvaluator, TradeLedger\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "model_eval = ModelEvaluator(base_path=Path(\"model_evaluation\"))\n",
    "# Setup paths\n",
    "base_path = Path(\"model_evaluation\")\n",
    "base_path.mkdir(exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "eval_path = base_path / f\"evaluation_{timestamp}\"\n",
    "eval_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Load your trained model\n",
    "model_manager = ModelManager()\n",
    "dataset_manager = DatasetManager()\n",
    "pair = \"EUR_USD\"\n",
    "\n",
    "model, version = model_manager.get_deployed_model(pair)\n",
    "\n",
    "# Load and split your data\n",
    "df = dataset_manager.load_parquet_dataset(pair)\n",
    "train_df, val_df, test_df = dataset_manager.split_dataset(df)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_metrics, test_ledger = model_eval.evaluate_model(\n",
    "    model=model,\n",
    "    df=test_df,\n",
    "    pair=pair,\n",
    "    output_path=eval_path / 'test'\n",
    ")\n",
    "\n",
    "# Print key metrics\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"Total Trades: {test_metrics['total_trades']}\")\n",
    "print(f\"Win Rate: {test_metrics['win_rate']:.2%}\")\n",
    "print(f\"Total PnL: {test_metrics['total_pnl']:.2f}\")\n",
    "print(f\"Sharpe Ratio: {test_metrics['sharpe_ratio']:.2f}\")\n",
    "print(f\"Max Drawdown: {test_metrics['max_drawdown']:.2%}\")\n",
    "\n",
    "# Analyze trade patterns\n",
    "test_df = test_ledger.to_dataframe()\n",
    "print(\"\\nTrade Analysis:\")\n",
    "print(\"\\nAverage PnL by Hour:\")\n",
    "print(test_df.groupby(test_df['entry_time'].dt.hour)['pnl'].mean().round(2))\n",
    "\n",
    "print(\"\\nPosition Type Performance:\")\n",
    "print(test_df.groupby('position_type').agg({\n",
    "    'pnl': ['count', 'mean', 'sum'],\n",
    "    'holding_period': 'mean'\n",
    "}).round(2))\n",
    "\n",
    "# Show the plots\n",
    "test_ledger.plot_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SB5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
