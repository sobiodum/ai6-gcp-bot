{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "source = '/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/unbiased/not_norm/train2/EUR_GBP_validate.parquet'\n",
    "df = pd.read_parquet(source)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from stable_baselines3 import PPO, A2C, SAC\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "from trading.environments.forex_env2_flat_simple import ForexTradingEnv\n",
    "# from trading.environments.forex_env_flat_multi_pair import MultipairForexTradingEnv\n",
    "\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from data_management.dataset_manager import DatasetManager\n",
    "from sb3_contrib import RecurrentPPO\n",
    "\n",
    "hourly_dir = \"/Volumes/ssd_fat2/ai6_trading_bot/datasets/1h/unbiased/not_norm/train/\"\n",
    "source_path = '/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/df_with_all_indics_unbiased/not_norm/train2/'\n",
    "source_dfs = [os.path.join(hourly_dir, f) for f in os.listdir(hourly_dir) if f.endswith('.parquet') and not f.startswith('.') and 'validate' not in f]\n",
    "\n",
    "eval_path = '/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/df_with_all_indics_unbiased/not_norm/train2/EUR_GBP_validate.parquet'\n",
    "sequence = 5\n",
    "saving_path = f'/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/df_with_all_indics_unbiased/not_norm/train/results/'\n",
    "os.makedirs(saving_path, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "def make_train_env():\n",
    "    env = ForexTradingEnv(\n",
    "        df_paths=source_dfs,\n",
    "        eval_mode=False,\n",
    "        sequence_length=sequence,\n",
    "\n",
    "\n",
    "    )\n",
    "    env = Monitor(env)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    env = VecNormalize(env, norm_obs=True, norm_reward=True)\n",
    "    return env\n",
    "\n",
    "def make_eval_env():\n",
    "    env = ForexTradingEnv(\n",
    "        df_paths=source_dfs,\n",
    "        eval_path=eval_path,\n",
    "        eval_mode=True,\n",
    "        pair='EUR_GBP',\n",
    "        sequence_length=sequence,\n",
    "\n",
    "\n",
    "    )\n",
    "    env = Monitor(env)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    env = VecNormalize(env, norm_obs=True, norm_reward=False)\n",
    "    env.training = False\n",
    "    return env\n",
    "\n",
    "train_env = make_train_env()\n",
    "eval_env = make_eval_env()\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=saving_path,\n",
    "    log_path=saving_path,\n",
    "    eval_freq=500_000,  # Adjust as needed\n",
    "    n_eval_episodes=5,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = PPO(\n",
    "    'MlpPolicy',\n",
    "    train_env,\n",
    "    verbose=0,\n",
    "    tensorboard_log=f'{saving_path}sequence_{sequence}_cont_space_PPO_20m_core_feat_v2_500k/',\n",
    ")\n",
    "# Define policy kwargs for the LSTM configuration\n",
    "policy_kwargs = dict(\n",
    "    # Network Architecture\n",
    "    net_arch=dict(\n",
    "        # Actor (policy) network\n",
    "        pi=[256, 128],  # Larger first layer to process high-dimensional input\n",
    "        # Critic (value) network\n",
    "        vf=[256, 128]   # Match actor architecture for balanced learning\n",
    "    ),\n",
    "    \n",
    "    # LSTM Configuration\n",
    "    lstm_hidden_size=256,      # Larger hidden size to capture complex patterns\n",
    "    n_lstm_layers=2,           # Multiple layers for hierarchical feature learning\n",
    "    enable_critic_lstm=True,   # Share temporal understanding between actor and critic\n",
    "    \n",
    "    # LSTM specific parameters\n",
    "    lstm_kwargs=dict(\n",
    "        dropout=0.2            # Slightly higher dropout for regularization\n",
    "    )\n",
    ")\n",
    "\n",
    "policy_kwargs_complex = dict(\n",
    "    net_arch=dict(\n",
    "        pi=[512, 256, 128],\n",
    "        vf=[512, 256, 128]\n",
    "    ),\n",
    "    lstm_hidden_size=512,\n",
    "    n_lstm_layers=3,\n",
    "    enable_critic_lstm=True,\n",
    "    lstm_kwargs=dict(\n",
    "        dropout=0.25\n",
    "    )\n",
    ")\n",
    "\n",
    "# model = RecurrentPPO(\n",
    "#     'MlpLstmPolicy',\n",
    "#     train_env,\n",
    "#     verbose=0,\n",
    "#     tensorboard_log=f'{saving_path}sequence_{sequence}_RecurrentPPO/',\n",
    "#     policy_kwargs=policy_kwargs,\n",
    "# )\n",
    "model.learn(\n",
    "    total_timesteps=20_000_000,  # Adjust as needed\n",
    "    callback=eval_callback\n",
    ")\n",
    "\n",
    "model.save(f'{saving_path}{sequence}_best_model_core.zip')\n",
    "train_env.save(f'{saving_path}{sequence}_vec_normalize_core.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = '/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/df_with_all_indics_unbiased/not_norm/train/'\n",
    "source_dfs = [os.path.join(source_path, f) for f in os.listdir(source_path) if f.endswith('.parquet') and not f.startswith('.')]\n",
    "source_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet('/Volumes/ssd_fat2/ai6_trading_bot/datasets/5min/df_with_all_indics_unbiased/not_norm/train/NZD_JPY_train.parquet')\n",
    "test.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SB5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
